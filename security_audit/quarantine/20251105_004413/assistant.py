#!/usr/bin/env python3
"""
Fused Terminal Chat & Command Assistant with OpenAI Integration and Selective Attention

A sophisticated assistant that combines:
- Battle-tested terminal operations from terminal_assistant.py
- OpenAI-powered conversational AI from assistant.py  
- Selective attention mechanisms for focused processing
- Dual modes: Chat (AI conversation) and Command (precise operations)
- Session persistence, experience tracking, and intelligent features
"""

import argparse
import asyncio
import hashlib
import inspect
import json
import logging
import os
import re
import subprocess
import time
from collections import Counter, defaultdict
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Any

# Import AI modules
from core.ai import ChatMessage, ModelConfig, ModelManager, OpenAIClient
# Import caching utilities
MISSING_ECHOES_DEPENDENCIES = False
try:
    from echoes.caching import TokenAwareCache, cached_function
except ModuleNotFoundError as exc:
    if exc.name == "pydantic_settings":
        MISSING_ECHOES_DEPENDENCIES = True
        from functools import lru_cache, wraps

        class TokenAwareCache:  # type: ignore[override]
            """Fallback cache when optional dependencies are unavailable."""

            def __init__(self, max_size: int = 1024, ttl: int = 3600, cache_dir: str = ".cache"):
                self.max_size = max_size

            def __call__(self, func):
                cached = lru_cache(maxsize=self.max_size)(func)

                @wraps(func)
                def wrapper(*args, **kwargs):
                    return cached(*args, **kwargs)

                # Expose cache management similar to TokenAwareCache
                wrapper.cache_clear = cached.cache_clear  # type: ignore[attr-defined]
                return wrapper

        def cached_function(func):
            """Fallback cached_function decorator using functools.lru_cache."""

            return TokenAwareCache()(func)

    else:
        raise

# Global cache instance
cache = TokenAwareCache(max_size=2048, ttl=86400)  # 1 day TTL


# Import consolidated selective attention utilities for simple functions

# Import smart_terminal components
try:
    from smart_terminal.core.feedback import FeedbackHandler
    from smart_terminal.core.predictor import CommandPredictor
    from smart_terminal.interface.terminal import TerminalInterface

    SMART_TERMINAL_AVAILABLE = True
except ImportError:
    SMART_TERMINAL_AVAILABLE = False

# Core dependencies with fallbacks
try:
    import requests

    REQUESTS_AVAILABLE = True
except ImportError:
    REQUESTS_AVAILABLE = False

try:
    from duckduckgo_search import DDGS

    DUCK_SEARCH_AVAILABLE = True
except ImportError:
    DUCK_SEARCH_AVAILABLE = False

try:
    import psutil

    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False

try:
    import asyncio

    from watchdog.events import FileSystemEventHandler
    from watchdog.observers import Observer

    WATCHDOG_AVAILABLE = True
except ImportError:
    WATCHDOG_AVAILABLE = False

# OpenAI Integration for ChatGPT Models
try:
    import openai
    from openai import OpenAI

    OPENAI_AVAILABLE = True
    print("ü§ñ OpenAI integration available")
except ImportError:
    OPENAI_AVAILABLE = False
    print("‚ö†Ô∏è OpenAI not available. Install with: pip install openai")
    openai = None
    OpenAI = None

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[logging.FileHandler("fused_assistant_logs.log"), logging.StreamHandler()],
)
logger = logging.getLogger("FusedAssistant")

# ============================================================================
# Core Selective Attention Function
# ============================================================================


def selective_attention(data, criteria=None, threshold=None, focus="auto"):
    """
    Core selective attention function - focuses processing on relevant data subsets.

    Args:
        data: Input data (list, dict, dataframe, etc.)
        criteria: Selection criteria function or pattern
        threshold: Numeric threshold for filtering
        focus: Focus mode ("auto", "high_value", "low_complexity", "urgent")

    Returns:
        Filtered data subset based on attention criteria
    """
    if data is None:
        return []

    # Auto-focus: determine best attention strategy
    if focus == "auto":
        if isinstance(data, list) and len(data) > 0:
            if all(isinstance(x, (int, float)) for x in data):
                # Numeric data - focus on even/odd patterns
                return [x for x in data if isinstance(x, (int, float)) and x % 2 == 0]
            elif all(isinstance(x, dict) for x in data):
                # Dict data - focus on high-priority items
                return [item for item in data if item.get("priority", 5) >= 7]
        elif isinstance(data, dict):
            # Single dict - focus on non-empty values
            return {k: v for k, v in data.items() if v is not None and v != ""}

    # High-value focus
    elif focus == "high_value":
        if isinstance(data, list) and all(isinstance(x, (int, float)) for x in data):
            if threshold:
                return [x for x in data if x >= threshold]
            else:
                # Top 20% of values
                sorted_data = sorted([x for x in data if isinstance(x, (int, float))])
                cutoff = len(sorted_data) * 0.8
                return (
                    sorted_data[int(cutoff) :]
                    if cutoff < len(sorted_data)
                    else sorted_data
                )

    # Low-complexity focus
    elif focus == "low_complexity":
        if isinstance(data, list):
            return [item for item in data if len(str(item)) < 100]  # Simple items

    # Urgent focus
    elif focus == "urgent":
        if isinstance(data, list) and all(isinstance(x, dict) for x in data):
            urgent_keywords = ["urgent", "critical", "emergency", "immediate"]
            return [
                item
                for item in data
                if any(keyword in str(item).lower() for keyword in urgent_keywords)
            ]

    # Custom criteria
    if criteria and callable(criteria):
        try:
            return [item for item in data if criteria(item)]
        except:
            return data

    # Fallback - return original data
    return data


def selective_attention_commands(commands, priority_threshold):
    """Selective attention for commands - focuses on high-priority commands"""
    if not commands:
        return []
    high_priority_commands = []

    for command in commands:
        if command.get("priority", 5) >= priority_threshold:
            high_priority_commands.append(command)

    return high_priority_commands


# ============================================================================
# Core Data Structures
# ============================================================================


class ActionType(Enum):
    """Types of actions the assistant can perform."""

    FILE_OPERATION = "file_operation"
    SYSTEM_COMMAND = "system_command"
    SEARCH = "search"
    CODE_EXECUTION = "code_execution"
    ANALYSIS = "analysis"
    COMMUNICATION = "communication"
    LEARNING = "learning"
    SELECTIVE_ATTENTION = "selective_attention"


class ComplexityLevel(Enum):
    """Complexity levels for task assessment."""

    SIMPLE = "simple"
    MODERATE = "moderate"
    COMPLEX = "complex"
    EXPERT = "expert"


@dataclass
class AttentionConfig:
    """Configuration for selective attention mechanisms."""

    attention_threshold: float = 0.7
    priority_weights: dict[str, float] = field(
        default_factory=lambda: {"high": 0.9, "medium": 0.6, "low": 0.3}
    )
    importance_factors: dict[str, float] = field(
        default_factory=lambda: {
            "complexity": 0.4,
            "urgency": 0.3,
            "resource_usage": 0.2,
            "user_preference": 0.1,
        }
    )
    enable_ml_explanation: bool = True
    max_attention_items: int = 10


@dataclass
class Experience:
    """Represents accumulated experience and learning."""

    domain: str
    success_rate: float = 0.0
    total_attempts: int = 0
    successful_attempts: int = 0
    patterns: dict[str, int] = field(default_factory=dict)
    best_practices: list[str] = field(default_factory=list)
    failure_modes: list[str] = field(default_factory=list)

    def record_attempt(
        self, success: bool, pattern: str = "", practice: str = "", failure: str = ""
    ):
        """Record an attempt and update experience."""
        self.total_attempts += 1
        if success:
            self.successful_attempts += 1
            if practice:
                self.best_practices.append(practice)
            if pattern:
                self.patterns[pattern] = self.patterns.get(pattern, 0) + 1
        else:
            if failure:
                self.failure_modes.append(failure)

        self.success_rate = self.successful_attempts / self.total_attempts

        # Keep only recent patterns and practices to manage memory
        if len(self.patterns) > 20:
            sorted_patterns = sorted(self.patterns.items(), key=lambda x: x[1])
            for pattern, count in sorted_patterns[: len(self.patterns) - 15]:
                del self.patterns[pattern]

        if len(self.best_practices) > 50:
            self.best_practices = self.best_practices[-30:]

        if len(self.failure_modes) > 30:
            self.failure_modes = self.failure_modes[-20:]


@dataclass
class CommandResult:
    """Result of command execution."""

    success: bool
    output: str = ""
    error: str = ""
    execution_time: float = 0.0
    complexity: ComplexityLevel = ComplexityLevel.SIMPLE
    confidence: float = 0.0
    suggestions: list[str] = field(default_factory=list)
    metadata: dict[str, Any] = field(default_factory=dict)
    attention_score: float = 0.0
    attention_filtered: bool = False


@dataclass
class ConversationMessage:
    """Message in conversation history."""

    role: str  # 'user' or 'assistant'
    content: str
    timestamp: datetime = field(default_factory=datetime.now)
    metadata: dict[str, Any] = field(default_factory=dict)


# ============================================================================
# Realtime Monitoring Classes
# ============================================================================


class RealtimeMonitor:
    """Simple realtime monitoring system for files, processes, and system resources."""

    def __init__(self):
        self.monitors = {}
        self.observers = {}
        self.is_monitoring = False
        self.monitor_callbacks = {}

    def start_file_monitoring(self, path: str, callback: callable = None) -> bool:
        """Start monitoring a file or directory for changes."""
        if not WATCHDOG_AVAILABLE or FileMonitorHandler is None:
            return False

        if path in self.monitors:
            return True  # Already monitoring

        try:
            event_handler = FileMonitorHandler(path, callback)
            observer = Observer()
            observer.schedule(event_handler, path, recursive=True)
            observer.start()

            self.monitors[path] = event_handler
            self.observers[path] = observer
            self.monitor_callbacks[path] = callback

            if not self.is_monitoring:
                self.is_monitoring = True

            return True
        except Exception as e:
            print(f"Failed to start file monitoring: {e}")
            return False

    def stop_file_monitoring(self, path: str) -> bool:
        """Stop monitoring a file or directory."""
        if path not in self.monitors:
            return False

        try:
            self.observers[path].stop()
            self.observers[path].join()
            del self.monitors[path]
            del self.observers[path]
            del self.monitor_callbacks[path]

            if not self.monitors:
                self.is_monitoring = False

            return True
        except Exception as e:
            print(f"Failed to stop file monitoring: {e}")
            return False

    def get_system_stats(self) -> dict[str, Any]:
        """Get current system statistics."""
        stats = {
            "timestamp": datetime.now().isoformat(),
            "monitoring_active": self.is_monitoring,
            "monitored_paths": list(self.monitors.keys()),
        }

        if PSUTIL_AVAILABLE:
            try:
                # CPU usage
                stats["cpu_percent"] = psutil.cpu_percent(interval=1)

                # Memory usage
                memory = psutil.virtual_memory()
                stats["memory"] = {
                    "total": memory.total,
                    "available": memory.available,
                    "percent": memory.percent,
                    "used": memory.used,
                }

                # Disk usage
                disk = psutil.disk_usage(".")
                stats["disk"] = {
                    "total": disk.total,
                    "free": disk.free,
                    "percent": disk.percent,
                }

                # Network I/O
                net_io = psutil.net_io_counters()
                stats["network"] = {
                    "bytes_sent": net_io.bytes_sent,
                    "bytes_recv": net_io.bytes_recv,
                    "packets_sent": net_io.packets_sent,
                    "packets_recv": net_io.packets_recv,
                }

                # Running processes count
                stats["process_count"] = len(psutil.pids())

            except Exception as e:
                stats["error"] = f"Failed to get system stats: {e}"

        return stats

    @cached_function
    def list_processes(self, filter_name: str = None) -> list[dict[str, Any]]:
        """List running processes with optional filtering."""
        if not PSUTIL_AVAILABLE:
            return [{"error": "psutil not available"}]

        processes = []
        try:
            for proc in psutil.process_iter(
                ["pid", "name", "cpu_percent", "memory_percent", "status"]
            ):
                try:
                    proc_info = proc.info
                    if (
                        filter_name
                        and filter_name.lower() not in proc_info["name"].lower()
                    ):
                        continue

                    processes.append(
                        {
                            "pid": proc_info["pid"],
                            "name": proc_info["name"],
                            "cpu_percent": proc_info["cpu_percent"] or 0,
                            "memory_percent": proc_info["memory_percent"] or 0,
                            "status": proc_info["status"],
                        }
                    )
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    continue

            # Sort by CPU usage
            processes.sort(key=lambda x: x["cpu_percent"], reverse=True)
            return processes[:20]  # Top 20 processes

        except Exception as e:
            return [{"error": f"Failed to list processes: {e}"}]

    def stop_monitoring(self):
        """Stop all monitoring activities."""
        for path in list(self.monitors.keys()):
            self.stop_file_monitoring(path)
        self.is_monitoring = False


try:
    import asyncio

    from watchdog.events import FileSystemEventHandler
    from watchdog.observers import Observer

    WATCHDOG_AVAILABLE = True

    class FileMonitorHandler(FileSystemEventHandler):
        """File system event handler for realtime monitoring."""

        def __init__(self, path: str, callback: callable = None):
            self.path = path
            self.callback = callback
            self.last_event_time = 0

        def on_modified(self, event):
            current_time = time.time()
            # Debounce events (ignore if less than 1 second apart)
            if current_time - self.last_event_time < 1:
                return

            self.last_event_time = current_time

            event_info = {
                "type": "modified",
                "path": event.src_path,
                "is_directory": event.is_directory,
                "timestamp": datetime.now().isoformat(),
            }

            if self.callback:
                try:
                    self.callback(event_info)
                except Exception as e:
                    print(f"Callback error: {e}")
            else:
                print(f"üìÅ File modified: {event.src_path}")

        def on_created(self, event):
            event_info = {
                "type": "created",
                "path": event.src_path,
                "is_directory": event.is_directory,
                "timestamp": datetime.now().isoformat(),
            }

            if self.callback:
                try:
                    self.callback(event_info)
                except Exception as e:
                    print(f"Callback error: {e}")
            else:
                print(f"üìÅ File created: {event.src_path}")

        def on_deleted(self, event):
            event_info = {
                "type": "deleted",
                "path": event.src_path,
                "is_directory": event.is_directory,
                "timestamp": datetime.now().isoformat(),
            }

            if self.callback:
                try:
                    self.callback(event_info)
                except Exception as e:
                    print(f"Callback error: {e}")
            else:
                print(f"üìÅ File deleted: {event.src_path}")

except ImportError:
    WATCHDOG_AVAILABLE = False
    FileMonitorHandler = None

# ============================================================================
# Enhanced Web Search Classes
# ============================================================================


class EnhancedWebSearcher:
    """Enhanced web search with multiple providers and better result processing."""

    def __init__(self):
        self.providers = {}
        self._initialize_providers()

    def _initialize_providers(self):
        """Initialize available search providers."""
        if DUCK_SEARCH_AVAILABLE:
            self.providers["duckduckgo"] = self._duck_search
        else:
            self.providers["duckduckgo"] = lambda q, n: [
                {"error": "DuckDuckGo search not available"}
            ]

        # Add more providers here in the future
        self.providers["google"] = self._google_search_fallback

    def search(
        self,
        query: str,
        provider: str = "duckduckgo",
        num_results: int = 5,
        include_metadata: bool = False,
    ) -> dict[str, Any]:
        """Perform web search with specified provider."""

        if provider not in self.providers:
            return {
                "error": f"Provider '{provider}' not available",
                "available_providers": list(self.providers.keys()),
            }

        try:
            results = self.providers[provider](query, num_results)

            response = {
                "query": query,
                "provider": provider,
                "num_results_requested": num_results,
                "num_results_returned": len(results),
                "results": results,
                "timestamp": datetime.now().isoformat(),
            }

            if include_metadata:
                response["metadata"] = {
                    "search_duration": 0.0,  # Could be measured
                    "provider_status": "available",
                    "results_filtered": False,
                }

            return response

        except Exception as e:
            return {
                "error": f"Search failed: {str(e)}",
                "query": query,
                "provider": provider,
            }

    def _duck_search(self, query: str, num_results: int) -> list[dict[str, str]]:
        """DuckDuckGo search implementation."""
        try:
            from duckduckgo_search import DDGS

            results = []
            with DDGS() as ddgs:
                for result in ddgs.text(query, max_results=num_results):
                    results.append(
                        {
                            "title": result.get("title", ""),
                            "url": result.get("href", ""),
                            "snippet": result.get("body", ""),
                            "source": "duckduckgo",
                        }
                    )
            return results
        except Exception as e:
            return [{"error": f"DuckDuckGo search failed: {str(e)}"}]

    def _google_search_fallback(
        self, query: str, num_results: int
    ) -> list[dict[str, str]]:
        """Google search fallback (placeholder for future implementation)."""
        return [
            {
                "title": "Google Search Integration",
                "url": f"https://www.google.com/search?q={query.replace(' ', '+')}",
                "snippet": "Google search integration not yet implemented. Use DuckDuckGo for now.",
                "source": "google_fallback",
            }
        ]

    def summarize_results(self, search_results: dict) -> dict[str, Any]:
        """Summarize search results for better readability."""
        if "error" in search_results:
            return search_results

        results = search_results.get("results", [])
        if not results:
            return {"summary": "No search results found"}

        # Extract key information
        summary = {
            "total_results": len(results),
            "top_domains": {},
            "key_topics": [],
            "has_error": any("error" in str(r) for r in results),
        }

        # Count domains
        for result in results:
            if "url" in result:
                try:
                    from urllib.parse import urlparse

                    domain = urlparse(result["url"]).netloc
                    summary["top_domains"][domain] = (
                        summary["top_domains"].get(domain, 0) + 1
                    )
                except:
                    pass

        # Sort domains by frequency
        summary["top_domains"] = dict(
            sorted(summary["top_domains"].items(), key=lambda x: x[1], reverse=True)[:5]
        )

        return summary


# ============================================================================
# Function Calling Classes
# ============================================================================


class FunctionCaller:
    """OpenAI function calling integration for tool execution."""

    def __init__(self, openai_client=None):
        self.openai_client = openai_client
        self.available_functions = {}
        self._register_default_functions()

    def _register_default_functions(self):
        """Register default functions that can be called by AI."""
        self.available_functions = {
            "get_system_info": {
                "function": self._get_system_info,
                "description": "Get basic system information including OS, CPU, memory",
                "parameters": {"type": "object", "properties": {}, "required": []},
            },
            "list_directory": {
                "function": self._list_directory,
                "description": "List contents of a directory",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "path": {
                            "type": "string",
                            "description": "Path to directory to list",
                        }
                    },
                    "required": ["path"],
                },
            },
            "read_file": {
                "function": self._read_file,
                "description": "Read contents of a file",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "filepath": {
                            "type": "string",
                            "description": "Path to file to read",
                        },
                        "max_lines": {
                            "type": "integer",
                            "description": "Maximum number of lines to read (optional)",
                        },
                    },
                    "required": ["filepath"],
                },
            },
            "web_search": {
                "function": self._web_search,
                "description": "Search the web for information",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "query": {"type": "string", "description": "Search query"},
                        "num_results": {
                            "type": "integer",
                            "description": "Number of results to return",
                            "default": 5,
                        },
                    },
                    "required": ["query"],
                },
            },
            "run_command": {
                "function": self._run_command,
                "description": "Execute a system command safely",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "command": {
                            "type": "string",
                            "description": "Command to execute",
                        },
                        "timeout": {
                            "type": "integer",
                            "description": "Command timeout in seconds",
                            "default": 30,
                        },
                    },
                    "required": ["command"],
                },
            },
        }

    def register_function(
        self, name: str, function: callable, description: str, parameters: dict
    ):
        """Register a custom function for AI to call."""
        self.available_functions[name] = {
            "function": function,
            "description": description,
            "parameters": parameters,
        }

    def get_function_schemas(self) -> list[dict]:
        """Get function schemas for OpenAI API."""
        schemas = []
        for name, func_info in self.available_functions.items():
            schemas.append(
                {
                    "name": name,
                    "description": func_info["description"],
                    "parameters": func_info["parameters"],
                }
            )
        return schemas

    def call_function(self, function_name: str, arguments: dict) -> dict[str, Any]:
        """Call a registered function with given arguments."""
        if function_name not in self.available_functions:
            return {"error": f"Function '{function_name}' not found"}

        try:
            func_info = self.available_functions[function_name]
            result = func_info["function"](**arguments)
            return {"success": True, "result": result, "function": function_name}
        except Exception as e:
            return {
                "error": f"Function execution failed: {str(e)}",
                "function": function_name,
            }

    def process_with_functions(
        self, messages: list, model: str = "gpt-4"
    ) -> dict[str, Any]:
        """Process messages with function calling enabled."""
        if not self.openai_client:
            return {"error": "OpenAI client not available"}

        try:
            response = self.openai_client.chat.completions.create(
                model=model,
                messages=messages,
                functions=self.get_function_schemas(),
                function_call="auto",
            )

            message = response.choices[0].message

            # Check if AI wants to call a function
            if hasattr(message, "function_call") and message.function_call:
                function_name = message.function_call.name
                function_args = json.loads(message.function_call.arguments)

                # Execute the function
                function_result = self.call_function(function_name, function_args)

                # Add function result to conversation
                messages.append(
                    {
                        "role": "assistant",
                        "content": None,
                        "function_call": {
                            "name": function_name,
                            "arguments": json.dumps(function_args),
                        },
                    }
                )

                messages.append(
                    {
                        "role": "function",
                        "name": function_name,
                        "content": json.dumps(function_result),
                    }
                )

                # Get final response
                final_response = self.openai_client.chat.completions.create(
                    model=model, messages=messages
                )

                return {
                    "response": final_response.choices[0].message.content,
                    "function_called": function_name,
                    "function_result": function_result,
                }
            else:
                return {"response": message.content}

        except Exception as e:
            return {"error": f"Function calling failed: {str(e)}"}

    # Default function implementations
    def _get_system_info(self) -> dict[str, Any]:
        """Get basic system information."""
        if not PSUTIL_AVAILABLE:
            return {"error": "System monitoring not available"}

        try:
            import platform

            return {
                "os": platform.system(),
                "os_version": platform.version(),
                "architecture": platform.architecture()[0],
                "cpu_count": psutil.cpu_count(),
                "memory_total": psutil.virtual_memory().total,
                "memory_available": psutil.virtual_memory().available,
            }
        except Exception as e:
            return {"error": str(e)}

    def _list_directory(self, path: str) -> list[str]:
        """List directory contents."""
        try:
            return [str(p) for p in Path(path).iterdir()]
        except Exception as e:
            return [f"Error: {str(e)}"]

    def _read_file(self, filepath: str, max_lines: int = None) -> str:
        """Read file contents."""
        try:
            with open(filepath, encoding="utf-8") as f:
                if max_lines:
                    lines = []
                    for i, line in enumerate(f):
                        if i >= max_lines:
                            break
                        lines.append(line)
                    return "".join(lines)
                else:
                    return f.read()
        except Exception as e:
            return f"Error reading file: {str(e)}"

    def _web_search(self, query: str, num_results: int = 5) -> list[dict[str, str]]:
        """Web search function."""
        searcher = EnhancedWebSearcher()
        result = searcher.search(query, num_results=num_results)
        return result.get("results", [])

    def _run_command(self, command: str, timeout: int = 30) -> dict[str, Any]:
        """Run system command safely."""
        try:
            result = subprocess.run(
                command, shell=True, capture_output=True, text=True, timeout=timeout
            )
            return {
                "returncode": result.returncode,
                "stdout": result.stdout,
                "stderr": result.stderr,
                "success": result.returncode == 0,
            }
        except subprocess.TimeoutExpired:
            return {"error": f"Command timed out after {timeout} seconds"}
        except Exception as e:
            return {"error": str(e)}


# ============================================================================
# Fused Assistant Class
# ============================================================================


class FusedAssistant:
    """
    Fused Terminal Chat & Command Assistant with OpenAI Integration and Selective Attention

    Combines battle-tested terminal operations with intelligent conversational AI
    and selective attention mechanisms for focused processing.
    Features dual-mode operation, experience tracking, and OpenAI-powered responses.
    """

    def __init__(self, openai_api_key: str | None = None):
        """Initialize the fused assistant with caching."""
        self.version = "2.1"
        self.session_id = hashlib.md5(
            f"{time.time()}{os.getpid()}".encode()
        ).hexdigest()[:8]

        # Initialize cache
        self.cache = cache
        self._init_caching()

        # Core values and principles
        self.values = {
            "reliability": "Consistent, dependable performance in all conditions",
            "efficiency": "Optimal resource usage and time management",
            "intelligence": "Smart reasoning and adaptive learning with AI augmentation",
            "transparency": "Clear communication and honest feedback",
            "safety": "Secure operations with error handling and recovery",
            "adaptability": "Learning from experience and improving over time",
            "helpfulness": "Focus on user needs and practical solutions",
            "selective_attention": "Focused processing on important aspects",
        }

        # Selective attention configuration
        self.attention_config = AttentionConfig()
        self.attention_stats = {
            "total_processed": 0,
            "attention_filtered": 0,
            "average_attention_score": 0.0,
            "filter_rate": 0.0,
        }

        # Experience tracking
        self.experience = {
            "file_operations": Experience("file_operations"),
            "system_commands": Experience("system_commands"),
            "web_search": Experience("web_search"),
            "code_execution": Experience("code_execution"),
            "data_analysis": Experience("data_analysis"),
            "debugging": Experience("debugging"),
            "automation": Experience("automation"),
            "ai_conversation": Experience("ai_conversation"),
        }

        # Session state
        self.conversation_history: list[ConversationMessage] = []
        self.command_history = []
        self.current_directory = Path.cwd()
        self.session_start_time = time.time()
        self.last_command_time = time.time()

        # Settings and configuration
        self.settings = {
            "verbose": True,
            "show_progress": True,
            "auto_retry": True,
            "learning_enabled": True,
            "context_aware": True,
            "multi_threaded": True,
            "timeout_seconds": 30,
            "max_retries": 3,
        }

        # AI Integration with Model Management
        self.openai_enabled = False
        self._ai_client = None
        self.model_preference = "local"
        self.available_models: dict[str, Any] = {}
        self.model_manager = ModelManager()

        # Initialize default models
        self._initialize_default_models()

        # Initialize OpenAI if available
        if OPENAI_AVAILABLE:
            self._initialize_openai(openai_api_key)
            if self.openai_enabled:
                self._fetch_available_models()

        # Set initial model
        self.dynamic_model_switching = True
        self.cost_optimization = True
        self.last_model_switch = time.time()

        # Initialize new feature components
        self.realtime_monitor = RealtimeMonitor()
        # Initialize function caller with OpenAI client if available
        self.function_caller = FunctionCaller(
            self._ai_client._client
            if (self.openai_enabled and self._ai_client)
            else None
        )

        # Initialize smart_terminal components
        self.smart_terminal_enabled = False
        self.smart_terminal_message = "Not available"

        if SMART_TERMINAL_AVAILABLE:
            try:
                self.smart_predictor = CommandPredictor()
                self.smart_feedback = FeedbackHandler()
                self.smart_terminal = TerminalInterface(
                    self.smart_predictor, self.smart_feedback
                )
                self.smart_terminal_enabled = True
                self.smart_terminal_message = "Available (predictor + feedback)"
            except RuntimeError as exc:
                logger.warning("Smart terminal disabled: %s", exc)
                self.smart_predictor = None
                self.smart_feedback = None
                self.smart_terminal = None
                self.smart_terminal_message = f"Disabled ({exc})"
        else:
            self.smart_predictor = None
            self.smart_feedback = None
            self.smart_terminal = None

        # Tool registry
        self.tools = self._initialize_base_tools()

        # Context and memory
        self.context = {
            "user_preferences": {},
            "common_tasks": [],
            "recent_files": [],
            "search_history": [],
            "failed_patterns": [],
        }

        # Performance metrics
        self.metrics = {
            "total_commands": 0,
            "successful_commands": 0,
            "failed_commands": 0,
            "average_execution_time": 0.0,
            "most_used_commands": Counter(),
            "success_by_category": defaultdict(int),
            "learning_progress": 0.0,
            "ai_conversations": 0,
            "attention_efficiency": 0.0,
        }

        logger.info(
            f"FusedAssistant v{self.version} initialized (Session: {self.session_id})"
        )
        print(
            f"ü§ñ Fused Assistant v{self.version} - Ready for Chat & Commands with Selective Attention"
        )
        print(f"üéØ Session ID: {self.session_id}")
        print(
            f"‚ö° Active: {len(self.tools)} tool categories, {len(self.experience)} experience domains"
        )
        print(
            f"üß† Attention: Threshold={self.attention_config.attention_threshold}, Max items={self.attention_config.max_attention_items}"
        )

        if self.openai_enabled:
            print(f"üß† OpenAI connected: {self.model_preference}")
        else:
            print("üß† Using local intelligence (OpenAI disabled)")

        print(f"‚å®Ô∏è Smart Terminal: {self.smart_terminal_message}")

        # Demonstrate selective attention on initialization
        self._demonstrate_selective_attention()

    def _init_caching(self) -> None:
        """Prepare caching subsystem and record availability state."""

        self.cache_enabled = False
        self.cache_backend = "memory"

        try:
            if hasattr(self.cache, "cache_dir"):
                cache_dir = getattr(self.cache, "cache_dir", None)
                if cache_dir is not None:
                    Path(cache_dir).mkdir(parents=True, exist_ok=True)
                    self.cache_backend = f"disk+memory ({cache_dir})"

            self.cache_enabled = True
        except Exception as exc:
            logger.warning("Cache initialization failed: %s", exc)
            self.cache_enabled = False

    def _initialize_default_models(self):
        """Initialize default model configurations."""
        # Add default models to the model manager
        self.model_manager.add_model(
            ModelConfig(
                id="gpt-3.5-turbo-1106",
                purpose="general",
                max_tokens=4096,
                cost_per_token=0.000002,
                priority=2,
            )
        )

        self.model_manager.add_model(
            ModelConfig(
                id="gpt-4-1106-preview",
                purpose="complex_queries",
                max_tokens=128000,
                cost_per_token=0.00003,
                priority=1,
            )
        )

        self.model_manager.add_model(
            ModelConfig(
                id="gpt-4-vision-preview",
                purpose="multimodal",
                max_tokens=128000,
                cost_per_token=0.00003,
                priority=3,
                supports_images=True,
            )
        )

        # Set default model
        self.model_manager.set_current_model("gpt-3.5-turbo-1106")

    def _initialize_openai(self, api_key: str | None = None):
        """Initialize OpenAI client with platform integration."""
        if not OPENAI_AVAILABLE:
            print("‚ö†Ô∏è OpenAI package not installed. Install with: pip install openai")
            return

        if not api_key:
            api_key = os.getenv("OPENAI_API_KEY")

        if not api_key:
            print(
                "‚ö†Ô∏è No OpenAI API key provided. Set OPENAI_API_KEY environment variable or use enable_openai command."
            )
            return

        try:
            # Initialize OpenAI client with model manager
            self._ai_client = OpenAIClient(
                api_key=api_key, model_manager=self.model_manager
            )
            self.openai_enabled = self._ai_client.initialize(api_key)

            if self.openai_enabled:
                self.openai_client = (
                    self._ai_client._client
                )  # Keep for backward compatibility
                print(
                    f"‚úÖ OpenAI connected. Available models: {', '.join([m.id for m in self.model_manager.list_models()][:5])}"
                )

        except Exception as e:
            print(f"‚ùå Failed to initialize OpenAI: {e}")
            self.openai_enabled = False
            self._ai_client = None
            self.openai_client = None

    def _fetch_available_models(self):
        """Fetch available models directly from OpenAI platform."""
        if not self.openai_client:
            return

        try:
            # Get models from OpenAI API
            models = self.openai_client.models.list()

            # Organize models by capability
            self.available_models = {}
            for model in models.data:
                model_id = model.id

                if self._is_chat_model(model_id):
                    self.available_models[model_id] = {
                        "id": model_id,
                        "created": model.created,
                        "owned_by": model.owned_by,
                        "type": "chat",
                    }

            # Set default model preference
            if "gpt-4" in self.available_models:
                self.model_preference = "gpt-4"
            elif "gpt-3.5-turbo" in self.available_models:
                self.model_preference = "gpt-3.5-turbo"

        except Exception as e:
            print(f"‚ö†Ô∏è Failed to fetch models: {e}")
            # Fallback to common models
            self.available_models = {
                "gpt-3.5-turbo": {"id": "gpt-3.5-turbo", "type": "chat"},
                "gpt-4": {"id": "gpt-4", "type": "chat"},
            }

    def _is_chat_model(self, model_id: str) -> bool:
        """Check if model is a chat completion model."""
        chat_patterns = [
            "gpt-3.5-turbo",
            "gpt-4",
            "gpt-4-turbo",
            "gpt-4o",
            "gpt-4o-mini",
        ]
        return any(pattern in model_id for pattern in chat_patterns)

    def _demonstrate_selective_attention(self):
        """Demonstrate selective attention capabilities on initialization."""
        sample_numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
        attention_result = selective_attention(sample_numbers)

        print("üîç Selective Attention Demo:")
        print(f"   Input: {sample_numbers}")
        print(f"   Focused on even numbers: {attention_result}")
        print(
            f"   Attention rate: {len(attention_result)}/{len(sample_numbers)} ({len(attention_result)/len(sample_numbers)*100:.1f}%)"
        )

    def _calculate_command_importance(self, command: str, args: list[str]) -> float:
        """Calculate importance score for a command using selective attention factors."""
        # Get command complexity as base score
        complexity = self._get_complexity_assessment(command, args)
        complexity_scores = {
            ComplexityLevel.SIMPLE: 0.2,
            ComplexityLevel.MODERATE: 0.5,
            ComplexityLevel.COMPLEX: 0.8,
            ComplexityLevel.EXPERT: 1.0,
        }
        base_score = complexity_scores[complexity]

        # Add urgency bonus
        urgency_bonus = 0.0
        urgent_keywords = [
            "delete",
            "remove",
            "stop",
            "kill",
            "emergency",
            "critical",
            "urgent",
        ]
        if any(
            keyword in " ".join([command] + args).lower() for keyword in urgent_keywords
        ):
            urgency_bonus = self.attention_config.importance_factors["urgency"]

        # Add resource intensity bonus
        resource_bonus = 0.0
        resource_keywords = [
            "download",
            "upload",
            "compile",
            "train",
            "analyze",
            "process",
        ]
        if any(
            keyword in " ".join([command] + args).lower()
            for keyword in resource_keywords
        ):
            resource_bonus = self.attention_config.importance_factors["resource_usage"]

        # Add user preference bonus (based on command frequency)
        preference_bonus = 0.0
        command_frequency = self.metrics["most_used_commands"].get(command, 0)
        if command_frequency > 0:
            preference_bonus = min(0.1, command_frequency / 100.0)  # Max 0.1 bonus

        # Calculate final score
        total_score = base_score + urgency_bonus + resource_bonus + preference_bonus

        # Ensure score is within bounds
        return min(1.0, max(0.0, total_score))

    def _apply_selective_attention_filter(self, command: str, args: list[str]) -> bool:
        """Apply selective attention filter to determine if command should be processed."""
        # Gather all relevant data for attention decision
        attention_data = {
            "command": command,
            "args": args,
            "importance_score": self._calculate_command_importance(command, args),
            "threshold": self.attention_config.attention_threshold,
            "session_commands": self.metrics["total_commands"],
            "success_rate": self.metrics["successful_commands"]
            / max(1, self.metrics["total_commands"]),
        }

        # Apply core selective attention function to make the decision
        selective_attention(
            attention_data,
            criteria=lambda x: x[0] in ["importance_score", "urgency", "success_rate"]
            and x[1] is not None,
            focus="high_value",
        )

        # Extract decision from attended factors
        importance_score = attention_data["importance_score"]
        threshold = attention_data["threshold"]

        # Update attention statistics
        self.attention_stats["total_processed"] += 1

        # Make attention-based decision
        should_process = selective_attention(
            [importance_score], threshold=threshold, focus="high_value"
        )

        if should_process:
            # Command passes attention filter
            self.attention_stats["average_attention_score"] = (
                self.attention_stats["average_attention_score"]
                * (self.attention_stats["total_processed"] - 1)
                + importance_score
            ) / self.attention_stats["total_processed"]
            return True
        else:
            # Command filtered out by selective attention
            self.attention_stats["attention_filtered"] += 1
            self.attention_stats["filter_rate"] = (
                self.attention_stats["attention_filtered"]
                / self.attention_stats["total_processed"]
            )
            logger.debug(
                f"Command filtered by selective attention: {command} (score: {importance_score:.3f})"
            )
            return False

    def get_attention_status(self) -> dict[str, Any]:
        """Get current selective attention statistics and configuration."""
        return {
            "attention_threshold": self.attention_config.attention_threshold,
            "max_attention_items": self.attention_config.max_attention_items,
            "enable_ml_explanation": self.attention_config.enable_ml_explanation,
            "statistics": self.attention_stats,
            "efficiency": {
                "filter_rate": self.attention_stats["filter_rate"],
                "average_score": self.attention_stats["average_attention_score"],
                "total_processed": self.attention_stats["total_processed"],
                "attention_filtered": self.attention_stats["attention_filtered"],
            },
        }

    def enable_openai(self, api_key: str) -> bool:
        """Enable OpenAI integration with provided API key."""
        try:
            self._initialize_openai(api_key)
            if self.openai_enabled and self.model_manager.get_current_model():
                print(
                    f"‚úÖ OpenAI enabled with model: {self.model_manager.get_current_model().id}"
                )
                return True
            return False
        except Exception as e:
            print(f"‚ùå Failed to enable OpenAI: {e}")
            return False

    def disable_openai(self):
        """Disable OpenAI integration."""
        self.openai_enabled = False
        self._ai_client = None
        self.openai_client = None
        print("‚úÖ OpenAI disabled. Using local intelligence.")

    def refresh_models(self):
        """Refresh the list of available models from OpenAI."""
        if not self.openai_enabled or not self._ai_client:
            print("OpenAI is not enabled or initialized.")
            return

        try:
            print("üîÑ Refreshing available models...")
            success = self._fetch_available_models()
            if success:
                models = [m.id for m in self.model_manager.list_models()]
                print(f"‚úÖ Available models: {', '.join(models)}")
            else:
                print("‚ö†Ô∏è Using default models. Could not fetch from API.")
        except Exception as e:
            print(f"‚ùå Failed to refresh models: {e}")

    def get_smart_suggestions(
        self, partial_command: str, num_suggestions: int = 5
    ) -> list[str]:
        """Get smart command suggestions using the predictor."""
        if not SMART_TERMINAL_AVAILABLE or not self.smart_predictor:
            return []

        try:
            suggestions = self.smart_predictor.get_suggestions(partial_command)
            return suggestions[:num_suggestions]
        except Exception as e:
            logger.error(f"Smart terminal suggestion error: {e}")
            return []

    def provide_smart_feedback(self, command: str, rating: int = None):
        """Provide feedback to the smart terminal system."""
        if not SMART_TERMINAL_AVAILABLE or not self.smart_feedback:
            return False

        try:
            if rating is not None:
                # Add rating feedback
                self.smart_feedback.add_rating(command, rating)
            else:
                # Add general command feedback
                self.smart_feedback.add_suggestion(command, accepted=True)
            return True
        except Exception as e:
            logger.error(f"Smart terminal feedback error: {e}")
            return False

    def start_smart_terminal_mode(self):
        """Start the smart terminal interface mode."""
        if not SMART_TERMINAL_AVAILABLE or not self.smart_terminal:
            print("‚ùå Smart Terminal not available")
            return

        print("‚å®Ô∏è Smart Terminal Mode Started")
        print("Features: Command prediction, tab completion, feedback collection")
        print("=" * 60)

        try:
            self.smart_terminal.run()
        except KeyboardInterrupt:
            print("\nüëã Smart Terminal mode interrupted")
        except Exception as e:
            print(f"‚ùå Smart Terminal error: {e}")
            logger.error(f"Smart terminal mode error: {e}")

        print("üëã Returned to main assistant menu")

    def get_command_help(self, command: str) -> str:
        """Get help information for a specific command."""
        # Command descriptions
        help_info = {
            # File operations
            "read": "Read file contents. Usage: read <filepath>",
            "write": "Write content to file. Usage: write <filepath> <content>",
            "list": "List files in directory. Usage: list [directory] [pattern]",
            "search": "Search files for text. Usage: search <query> [directory]",
            "analyze": "Analyze file characteristics. Usage: analyze <filepath>",
            "diff": "Compare two files. Usage: diff <file1> <file2>",
            "backup": "Create backup of file. Usage: backup <filepath> [backup_dir]",
            "create": "Create new file. Usage: create <filepath> [content]",
            "delete": "Delete file. Usage: delete <filepath>",
            "move": "Move file. Usage: move <source> <destination>",
            "copy": "Copy file. Usage: copy <source> <destination>",
            # System commands
            "execute": "Execute system command. Usage: execute <command>",
            "process_info": "Get process information. Usage: process_info [pid]",
            "disk_usage": "Get disk usage. Usage: disk_usage [path]",
            "network_status": "Check network connectivity. Usage: network_status",
            "system_info": "Get system information. Usage: system_info",
            "env_vars": "List environment variables. Usage: env_vars",
            "running_processes": "List running processes. Usage: running_processes",
            # Web operations
            "web_search": "Search the web. Usage: web_search <query> [num_results]",
            "download": "Download file from URL. Usage: download <url> <filepath>",
            "http_status": "Check HTTP status. Usage: http_status <url> [method]",
            "curl": "Make HTTP request. Usage: curl <url> [method] [headers] [data]",
            "api_call": "Make API call. Usage: api_call <endpoint> [method] [headers] [data]",
            # Code operations
            "run": "Run code. Usage: run <code> [language]",
            "lint": "Lint code file. Usage: lint <filepath>",
            "format": "Format code file. Usage: format <filepath>",
            "test": "Run tests. Usage: test [filepath|directory] [pattern]",
            "debug": "Debug code. Usage: debug <filepath>",
            "profile": "Profile code performance. Usage: profile <filepath>",
            # Data operations
            "parse_csv": "Parse CSV file. Usage: parse_csv <filepath> [delimiter]",
            "parse_json": "Parse JSON file. Usage: parse_json <filepath>",
            "analyze_data": "Analyze data. Usage: analyze_data <data>",
            "clean_data": "Clean data. Usage: clean_data <data> <operations>",
            "statistics": "Get data statistics. Usage: statistics <data>",
            # Analysis operations
            "review_code": "Review code quality. Usage: review_code <filepath> [review_type]",
            "security_scan": "Security scan. Usage: security_scan <filepath>",
            "analyze_performance": "Performance analysis. Usage: analyze_performance <filepath>",
            "check_dependencies": "Check dependencies. Usage: check_dependencies [directory] [dependency_file]",
            # Assistant commands
            "help": "Show help information. Usage: help [command]",
            "status": "Show assistant status. Usage: status",
            "history": "Show command history. Usage: history [count]",
            "clear": "Clear screen. Usage: clear",
            "save_session": "Save current session. Usage: save_session [filepath]",
            "load_session": "Load previous session. Usage: load_session <filepath>",
            "metrics": "Show performance metrics. Usage: metrics",
            "tools": "List available tools. Usage: tools",
            "train": "Train assistant with enhanced logic. Usage: train [training_data_path]",
            # OpenAI commands
            "enable openai": "Enable OpenAI integration. Usage: enable openai <api_key>",
            "disable openai": "Disable OpenAI integration. Usage: disable openai",
            "set model": "Set OpenAI model. Usage: set model <model_name>",
            "refresh models": "Refresh available models. Usage: refresh models",
            # Selective attention commands
            "attention status": "Show selective attention statistics. Usage: attention status",
            "attention threshold": "Set attention threshold. Usage: attention threshold <value>",
        }

        return help_info.get(
            command,
            f"No help available for '{command}'. Type 'help' to see all commands.",
        )

    def execute_command(self, command_line: str) -> CommandResult:
        """Execute a command line with full intelligence, experience, and selective attention."""
        start_time = time.time()

        try:
            # Parse command line
            parts = command_line.strip().split()
            if not parts:
                return CommandResult(
                    success=False,
                    error="Empty command",
                    complexity=ComplexityLevel.SIMPLE,
                    confidence=0.0,
                    attention_filtered=False,
                )

            command = parts[0].lower()
            args = parts[1:]

            # Apply selective attention filter (skip for attention management commands)
            attention_bypass_commands = ["attention", "status", "help", "metrics"]
            should_apply_attention = not any(
                bypass in command for bypass in attention_bypass_commands
            )

            if should_apply_attention and not self._apply_selective_attention_filter(
                command, args
            ):
                importance_score = self._calculate_command_importance(command, args)
                return CommandResult(
                    success=False,
                    error=f"Command filtered by selective attention (importance score: {importance_score:.3f} < threshold: {self.attention_config.attention_threshold})",
                    complexity=self._get_complexity_assessment(command, args),
                    confidence=0.0,
                    attention_score=importance_score,
                    attention_filtered=True,
                )

            # Update context
            self.context["last_command"] = command
            self.context["last_command_time"] = datetime.now().isoformat()

            # Log command for learning
            self.command_history.append(
                {
                    "timestamp": datetime.now().isoformat(),
                    "command": command_line,
                    "command_name": command,
                    "args": args,
                    "session_id": self.session_id,
                    "attention_score": self._calculate_command_importance(
                        command, args
                    ),
                }
            )

            # Keep only recent history
            if len(self.command_history) > 100:
                self.command_history = self.command_history[-50:]

            # Execute the command
            result = self._execute_command_internal(command, args)
            result.execution_time = time.time() - start_time
            result.attention_score = self._calculate_command_importance(command, args)
            result.attention_filtered = False

            # Generate suggestions
            result.suggestions = self._generate_suggestions(command, args, result)

            # Record experience
            self._record_experience(command, args, result)

            # Update metrics
            self._update_metrics(result.execution_time)

            # Provide feedback to smart terminal predictor
            if SMART_TERMINAL_AVAILABLE and self.smart_predictor and result.success:
                try:
                    self.smart_predictor.update_command(command_line)
                    if self.smart_feedback:
                        # Add positive feedback for successful commands
                        self.smart_feedback.add_suggestion(command_line, accepted=True)
                except Exception as e:
                    logger.debug(f"Smart terminal feedback error: {e}")

            # Store result in conversation history
            self.conversation_history.append(
                ConversationMessage(
                    role="user", content=command_line, metadata={"result": result}
                )
            )

            # Keep only recent conversation
            if len(self.conversation_history) > 50:
                self.conversation_history = self.conversation_history[-25:]

            logger.info(
                f"Command '{command}' executed in {result.execution_time:.2f}s with {'success' if result.success else 'failure'} (attention score: {result.attention_score:.3f})"
            )

            return result

        except Exception as e:
            logger.error(f"Error executing command '{command_line}': {e}")
            return CommandResult(
                success=False,
                error=str(e),
                execution_time=time.time() - start_time,
                complexity=ComplexityLevel.SIMPLE,
                confidence=0.0,
                attention_filtered=False,
            )

    def _execute_command_internal(self, command: str, args: list[str]) -> CommandResult:
        """Internal command execution with proper error handling."""
        start_time = time.time()

        try:
            complexity = self._get_complexity_assessment(command, args)
            confidence = self._assess_confidence(command, args)

            # Find and execute the command
            for category, tools in self.tools.items():
                if command in tools:
                    tool_function = tools[command]

                    # Validate arguments
                    if not self._validate_arguments(command, args, tool_function):
                        return CommandResult(
                            success=False,
                            error="Invalid arguments provided",
                            complexity=complexity,
                            confidence=0.3,
                        )

                    # Execute the tool
                    if inspect.iscoroutinefunction(tool_function):
                        result_data = asyncio.run(tool_function(*args))
                    else:
                        result_data = tool_function(*args)

                    execution_time = time.time() - start_time

                    # Format result
                    if isinstance(result_data, dict):
                        output = json.dumps(result_data, indent=2)
                    else:
                        output = str(result_data)

                    return CommandResult(
                        success=True,
                        output=output,
                        execution_time=execution_time,
                        complexity=complexity,
                        confidence=confidence,
                    )

            # Command not found - try AI interpretation
            if self.openai_enabled and self.openai_client:
                ai_response = self._generate_chatgpt_response(
                    f"Execute command: {command} {' '.join(args)}"
                )
                return CommandResult(
                    success=True,
                    output=ai_response,
                    execution_time=time.time() - start_time,
                    complexity=complexity,
                    confidence=confidence
                    * 0.8,  # Slightly lower confidence for AI interpretation
                )

            # Command not found and no AI
            return CommandResult(
                success=False,
                error=f"Command '{command}' not found. Type 'help' for available commands.",
                complexity=complexity,
                confidence=0.0,
            )

        except Exception as e:
            return self._handle_error(command, args, e)

    # ============================================================================
    # Chat Mode with OpenAI Integration
    # ============================================================================

    def chat_mode(self):
        """Start interactive chat mode with OpenAI integration."""
        print("ü§ñ Chat Mode Started - Type 'quit' or 'exit' to return to menu")
        print("=" * 60)

        while True:
            try:
                user_input = input("üí¨ You: ").strip()

                if not user_input:
                    continue

                if user_input.lower() in ["quit", "exit", "q"]:
                    print("üëã Returning to main menu...")
                    break

                # Process chat message
                response = self._process_chat_message(user_input)
                print(f"ü§ñ Assistant: {response}")

                # Add to conversation history
                self.conversation_history.append(
                    ConversationMessage(role="user", content=user_input)
                )
                self.conversation_history.append(
                    ConversationMessage(role="assistant", content=response)
                )

                # Update metrics
                self.metrics["ai_conversations"] += 1

            except KeyboardInterrupt:
                print("\nüëã Interrupted. Use 'quit' to exit properly.")
            except Exception as e:
                print(f"‚ùå Chat error: {e}")
                logger.error(f"Chat mode error: {e}")

    def _process_chat_message(self, message: str) -> str:
        """Process chat message with command interpretation and AI response."""
        # Check for OpenAI commands first
        if message.lower().startswith("enable openai"):
            parts = message.split()
            if len(parts) >= 3:
                api_key = parts[2]
                success = self.enable_openai(api_key)
                return "‚úÖ OpenAI enabled!" if success else "‚ùå Failed to enable OpenAI"
            else:
                return "Please provide API key: 'enable openai your-api-key-here'"

        elif message.lower() == "disable openai":
            self.disable_openai()
            return "‚úÖ OpenAI disabled. Using local intelligence."

        elif message.lower().startswith("set model"):
            parts = message.split()
            if len(parts) >= 3:
                model_name = parts[2]
                success = self.set_model(model_name)
                return (
                    f"‚úÖ Model set to {model_name}"
                    if success
                    else "‚ùå Failed to set model"
                )
            else:
                return "Please provide model name: 'set model gpt-4'"

        elif message.lower().startswith("train"):
            parts = message.split()
            training_data = None
            if len(parts) >= 3:
                training_data = parts[2]
            result = self.train_assistant(training_data)
            if result["success"]:
                return f"‚úÖ Training complete! Enhanced with {len(result['new_features'])} new capabilities"
            else:
                return f"‚ùå Training failed: {result['error']}"

        elif message.lower() == "refresh models":
            self.refresh_models()
            return f"‚úÖ Refreshed {len(self.available_models)} models"

        # Check for embedded commands
        if message.lower().startswith("run "):
            command = message[4:]  # Remove "run "
            result = self.execute_command(command)
            if result.success:
                return f"‚úÖ Command executed: {result.output}"
            else:
                return f"‚ùå Command failed: {result.error}"

        # Generate AI response
        if self.openai_enabled and self.openai_client:
            return self._generate_chatgpt_response(message)
        else:
            return self._generate_local_response(message)

    def _generate_chatgpt_response(self, message: str) -> str:
        """Generate response using OpenAI ChatGPT.

        This is a shim for backward compatibility that uses the new OpenAIClient.
        """
        if not self._ai_client or not self.openai_enabled:
            return "OpenAI client not initialized. Please check your API key and try again."

        try:
            # Build system message with context
            system_message = f"""You are Fused Assistant v{self.version}, a sophisticated AI that combines terminal operations with intelligent conversation. 

Current capabilities:
- File operations: read, write, analyze, search files
- System commands: execute processes, check system info
- Web operations: search, download, API calls
- Code operations: run, lint, test, debug code
- Data operations: parse CSV/JSON, analyze data
- Analysis: code review, security scan, performance analysis

Current session: {self.session_id}
Available tools: {len(self.tools)} categories
OpenAI enabled: {self.openai_enabled}

Be helpful, concise, and practical. If the user asks for operations you can perform, suggest the appropriate commands."""

            # Convert conversation history to ChatMessage objects
            chat_messages = [
                ChatMessage(role=msg.role, content=msg.content)
                for msg in self.conversation_history[-5:]  # Last 5 messages for context
            ]

            # Add current message
            chat_messages.append(ChatMessage(role="user", content=message))

            # Generate response using the OpenAIClient
            response = self._ai_client.generate_text(
                message,
                system_message=system_message,
                model=self.model_manager.get_current_model().id
                if self.model_manager.get_current_model()
                else None,
                max_tokens=1000,
                temperature=0.7,
            )

            return response.strip()

        except Exception as e:
            logger.error(f"Error generating response: {e}")
            return f"‚ùå Error generating response: {str(e)}"

    def _generate_local_response(self, message: str) -> str:
        """Generate response using local intelligence."""
        message_lower = message.lower()

        # Help requests
        if any(
            word in message_lower for word in ["help", "commands", "what can you do"]
        ):
            return """I can help you with:
üìÅ File operations: read, write, search, analyze files
üîß System commands: execute processes, check system info  
üåê Web operations: search online, download files
üíª Code operations: run, lint, test, debug code
üìä Data operations: parse CSV/JSON, analyze data
üîç Analysis: code review, security scan, performance analysis

Type 'run <command>' to execute any operation, or 'enable openai <key>' for AI-powered responses."""

        # Status requests
        if any(word in message_lower for word in ["status", "how are you"]):
            return f"""Fused Assistant v{self.version} - Status:
üéØ Session: {self.session_id}
‚ö° Commands executed: {self.metrics['total_commands']}
‚úÖ Success rate: {(self.metrics['successful_commands'] / max(1, self.metrics['total_commands'])) * 100:.1f}%
üß† AI mode: {'OpenAI ' + self.model_preference if self.openai_enabled else 'Local intelligence'}
üõ†Ô∏è Tools available: {sum(len(category) for category in self.tools.values())}"""

        # File-related questions
        if any(word in message_lower for word in ["file", "read", "write"]):
            return "I can help with file operations! Use 'run read <filename>' to read a file, 'run write <filename> <content>' to write, or 'run analyze <filename>' to analyze file contents."

        # System-related questions
        if any(word in message_lower for word in ["system", "process", "command"]):
            return "I can execute system commands! Use 'run execute <command>' to run any system command, 'run system_info' for system details, or 'run process_info' for process information."

        # Default response
        return "I'm here to help! Type 'help' for available commands, 'enable openai <key>' for AI-powered responses, or 'run <command>' to execute operations."

    # ============================================================================
    # Command Mode
    # ============================================================================

    def command_mode(self):
        """Start interactive command mode."""
        print("‚ö° Command Mode Started")
        print("=" * 60)
        print("Enter precise commands. Type 'help' for available commands.")
        print("Type 'quit' or 'exit' to return to menu.")
        print("=" * 60)

        while True:
            try:
                command = input("‚ö° Command: ").strip()

                if not command:
                    continue

                if command.lower() in ["quit", "exit", "q"]:
                    print("üëã Returning to main menu...")
                    break

                if command.lower() == "help":
                    self._show_command_help()
                    continue

                # Execute command
                result = self.execute_command(command)

                # Display result
                if result.success:
                    print(f"‚úÖ Success ({result.execution_time:.2f}s)")
                    if result.output:
                        print(result.output)
                else:
                    print(f"‚ùå Failed ({result.execution_time:.2f}s)")
                    print(f"Error: {result.error}")

                # Show suggestions
                if result.suggestions:
                    print("üí° Suggestions:")
                    for suggestion in result.suggestions:
                        print(f"  - {suggestion}")

            except KeyboardInterrupt:
                print("\nüëã Interrupted. Use 'quit' to exit properly.")
            except Exception as e:
                print(f"‚ùå Command error: {e}")
                logger.error(f"Command mode error: {e}")

    def _show_command_help(self):
        """Show available commands in command mode."""
        print("\nüìã Available Commands:")
        for category, commands in self.tools.items():
            category_name = category.replace("_", " ").title()
            print(f"\n  {category_name}:")
            for cmd in list(commands.keys())[:5]:  # Show first 5 commands
                print(f"    - {cmd}")
        print(
            f"\nüí° Total: {sum(len(category) for category in self.tools.values())} commands available"
        )
        print("üìñ Use 'help <command>' for specific command help")

    # ============================================================================
    # Tool Implementations (Simplified versions for demo)
    # ============================================================================

    @cached_function
    def _read_file(self, filepath: str) -> str:
        """Read file contents with caching."""
        cache_key = f"read_file_{hashlib.md5(filepath.encode()).hexdigest()}"

        # Check cache first
        if (
            hasattr(self, "_file_content_cache")
            and cache_key in self._file_content_cache
        ):
            # Check if file has been modified since caching
            cached_data = self._file_content_cache[cache_key]
            try:
                mtime = os.path.getmtime(filepath)
                if mtime <= cached_data["mtime"]:
                    logger.debug(f"Cache hit for file: {filepath}")
                    return cached_data["content"]
            except OSError:
                pass  # File might not exist anymore

        try:
            with open(filepath, "r", encoding="utf-8") as f:
                content = f.read()

            # Cache the content
            if not hasattr(self, "_file_content_cache"):
                self._file_content_cache = {}

            self._file_content_cache[cache_key] = {
                "content": content,
                "mtime": os.path.getmtime(filepath),
                "timestamp": time.time(),
            }

            # Limit cache size
            if len(self._file_content_cache) > 500:  # Limit to 500 files
                # Remove oldest entries
                oldest_key = min(
                    self._file_content_cache.keys(),
                    key=lambda k: self._file_content_cache[k]["timestamp"],
                )
                del self._file_content_cache[oldest_key]

            return content

        except Exception as e:
            logger.error(f"Error reading file {filepath}: {e}")
            return ""

    def _write_file(self, filepath: str, content: str) -> dict[str, Any]:
        """Write content to file."""
        try:
            Path(filepath).parent.mkdir(parents=True, exist_ok=True)
            with open(filepath, "w", encoding="utf-8") as f:
                f.write(content)
            return {"success": True, "filepath": filepath, "size": len(content)}
        except Exception as e:
            return {"error": str(e)}

    def _analyze_file_with_args(self, *args) -> dict[str, Any]:
        """Analyze file with multiple arguments joined as filepath."""
        if not args:
            return {"error": "No filepath provided for analysis"}

        filepath = " ".join(args)
        return self._analyze_file(filepath)

    def _analyze_file(self, filepath: str) -> dict[str, Any]:
        """Analyze file characteristics."""
        path = Path(filepath)
        if not path.exists():
            return {"error": f"File {filepath} does not exist"}

        stat = path.stat()
        analysis = {
            "path": str(path),
            "size": stat.st_size,
            "extension": path.suffix,
            "type": "unknown",
        }

        if path.suffix in [".py"]:
            analysis.update(self._analyze_python_file(path))
        elif path.suffix in [".json"]:
            analysis.update(self._analyze_json_file(path))

        return analysis

    def _analyze_python_file(self, path: Path) -> dict[str, Any]:
        """Analyze Python file."""
        try:
            with open(path, encoding="utf-8") as f:
                content = f.read()

            lines = content.split("\n")
            return {
                "type": "python",
                "lines": len(lines),
                "functions": len(re.findall(r"def\s+\w+", content)),
                "classes": len(re.findall(r"class\s+\w+", content)),
                "imports": len(re.findall(r"^(import|from)\s+", content, re.MULTILINE)),
            }
        except Exception as e:
            return {"type": "python", "error": str(e)}

    def _analyze_json_file(self, path: Path) -> dict[str, Any]:
        """Analyze JSON file."""
        try:
            with open(path, encoding="utf-8") as f:
                data = json.load(f)

            return {
                "type": "json",
                "keys": len(data) if isinstance(data, dict) else 0,
                "is_valid": True,
            }
        except Exception as e:
            return {"type": "json", "error": str(e), "is_valid": False}

    def _list_files(self, directory: str = ".") -> list[str]:
        """List files in directory."""
        try:
            path = Path(directory)
            if not path.exists():
                return [f"Error: Directory {directory} does not exist"]

            return [str(p) for p in path.iterdir() if p.is_file()]
        except Exception as e:
            return [f"Error listing files: {str(e)}"]

    def _execute_command(self, command: str) -> str:
        """Execute system command."""
        try:
            result = subprocess.run(
                command, shell=True, capture_output=True, text=True, timeout=30
            )
            if result.returncode == 0:
                return result.stdout
            else:
                return f"Command failed with return code {result.returncode}: {result.stderr}"
        except subprocess.TimeoutExpired:
            return "Command timed out after 30 seconds"
        except Exception as e:
            return f"Error executing command: {str(e)}"

    def _web_search(self, query: str, num_results: int = 5) -> list[dict[str, str]]:
        """Search web using DuckDuckGo."""
        if not DUCK_SEARCH_AVAILABLE:
            return [
                {
                    "error": "DuckDuckGo search not available. Install with: pip install duckduckgo-search"
                }
            ]

        try:
            from duckduckgo_search import DDGS

            results = []
            with DDGS() as ddgs:
                for result in ddgs.text(query, max_results=num_results):
                    results.append(
                        {
                            "title": result.get("title", ""),
                            "url": result.get("href", ""),
                            "snippet": result.get("body", ""),
                        }
                    )
                return results
        except Exception as e:
            return [{"error": f"Search failed: {str(e)}"}]

    # Placeholder implementations for other tools
    def _create_file(self, filepath: str, content: str = "") -> dict[str, Any]:
        return self._write_file(filepath, content)

    def _delete_file(self, filepath: str) -> dict[str, Any]:
        try:
            Path(filepath).unlink()
            return {"success": True, "deleted": filepath}
        except Exception as e:
            return {"error": str(e)}

    def _search_files(self, query: str, directory: str = ".") -> list[str]:
        return ["Search functionality not implemented in demo"]

    def _compare_files(self, file1: str, file2: str) -> dict[str, Any]:
        return {"message": "File comparison not implemented in demo"}

    def _backup_file(self, filepath: str) -> dict[str, Any]:
        return {"message": "File backup not implemented in demo"}

    def _move_file(self, source: str, destination: str) -> dict[str, Any]:
        return {"message": "File move not implemented in demo"}

    def _copy_file(self, source: str, destination: str) -> dict[str, Any]:
        return {"message": "File copy not implemented in demo"}

    def _get_process_info(self, pid: int = None) -> dict[str, Any]:
        return {"message": "Process info not implemented in demo"}

    def _get_disk_usage(self, path: str = ".") -> dict[str, Any]:
        return {"message": "Disk usage not implemented in demo"}

    def _check_network(self) -> dict[str, Any]:
        return {"message": "Network check not implemented in demo"}

    def _get_system_info(self) -> dict[str, Any]:
        return {"message": "System info not implemented in demo"}

    def _get_env_vars(self) -> dict[str, str]:
        return dict(os.environ)

    def _get_running_processes(self) -> list[str]:
        return ["Process listing not implemented in demo"]

    def _download_file(self, url: str, filepath: str = None) -> dict[str, Any]:
        return {"message": "File download not implemented in demo"}

    def _check_http_status(self, url: str) -> dict[str, Any]:
        return {"message": "HTTP status check not implemented in demo"}

    def _curl_request(self, url: str, method: str = "GET") -> dict[str, Any]:
        return {"message": "Curl request not implemented in demo"}

    def _make_api_call(self, endpoint: str, method: str = "GET") -> dict[str, Any]:
        return {"message": "API call not implemented in demo"}

    def _run_code(self, code: str, language: str = "python") -> str:
        return "Code execution not implemented in demo"

    def _lint_code(self, filepath: str) -> dict[str, Any]:
        return {"message": "Code linting not implemented in demo"}

    def _format_code(self, filepath: str) -> dict[str, Any]:
        return {"message": "Code formatting not implemented in demo"}

    def _run_tests(self, directory: str = ".") -> dict[str, Any]:
        return {"message": "Test running not implemented in demo"}

    def _debug_code(self, filepath: str) -> dict[str, Any]:
        return {"message": "Code debugging not implemented in demo"}

    def _profile_code(self, filepath: str) -> dict[str, Any]:
        return {"message": "Code profiling not implemented in demo"}

    def _parse_csv(self, filepath: str) -> dict[str, Any]:
        return {"message": "CSV parsing not implemented in demo"}

    def _parse_json(self, filepath: str) -> dict[str, Any]:
        return self._analyze_json_file(Path(filepath))

    def _analyze_data(self, data: str) -> dict[str, Any]:
        return {"message": "Data analysis not implemented in demo"}

    def _clean_data(self, data: str) -> dict[str, Any]:
        return {"message": "Data cleaning not implemented in demo"}

    def _get_statistics(self, data: str) -> dict[str, Any]:
        return {"message": "Statistics not implemented in demo"}

    def _review_code(self, filepath: str) -> dict[str, Any]:
        return {"message": "Code review not implemented in demo"}

    def _security_scan(self, filepath: str) -> dict[str, Any]:
        return {"message": "Security scan not implemented in demo"}

    def _analyze_performance(self, filepath: str) -> dict[str, Any]:
        return {"message": "Performance analysis not implemented in demo"}

    def _check_dependencies(self, directory: str = ".") -> dict[str, Any]:
        return {"message": "Dependency check not implemented in demo"}

    def _show_help(self, command: str = None) -> str:
        """Show help information."""
        if command:
            return f"Help for '{command}': Use this command to..."
        else:
            return """Fused Assistant Help:

üìÅ File Operations: read, write, create, delete, list, search, analyze, diff, backup, move, copy
üîß System Commands: execute, process_info, disk_usage, network_status, system_info, env_vars, running_processes  
üåê Web Operations: web_search, download, http_status, curl, api_call
üíª Code Operations: run, lint, format, test, debug, profile
üìä Data Operations: parse_csv, parse_json, analyze_data, clean_data, statistics
üîç Analysis: review_code, security_scan, analyze_performance, check_dependencies
üì° Realtime: start_file_monitor, stop_file_monitor, system_stats, list_processes, stop_monitoring
üîé Enhanced Web: enhanced_web_search, summarize_search, search_providers
üõ†Ô∏è Function Calling: register_function, list_functions, call_function, function_chat
ü§ñ Assistant: help, status, history, clear, save_session, load_session, metrics, tools, train

üí° Usage: Type command name followed by arguments
üß† AI: Enable OpenAI with 'enable openai <key>' for intelligent responses"""

    def train_assistant(self, training_data_path: str | None = None) -> dict[str, Any]:
        """Train the assistant with enhanced logic and capabilities.

        This function incorporates the battle-tested terminal assistant logic
        to enhance the current assistant's capabilities.

        Args:
            training_data_path: Optional path to training data file

        Returns:
            Dict with training results and updated capabilities
        """
        try:
            print("üß† Training Assistant with Enhanced Logic...")

            # Enhanced experience tracking with more domains
            enhanced_experience = {
                "file_operations": self.experience.get(
                    "file_operations", Experience("file_operations")
                ),
                "system_commands": self.experience.get(
                    "system_commands", Experience("system_commands")
                ),
                "web_search": self.experience.get(
                    "web_search", Experience("web_search")
                ),
                "code_execution": self.experience.get(
                    "code_execution", Experience("code_execution")
                ),
                "data_analysis": self.experience.get(
                    "data_analysis", Experience("data_analysis")
                ),
                "debugging": self.experience.get("debugging", Experience("debugging")),
                "automation": self.experience.get(
                    "automation", Experience("automation")
                ),
                # New enhanced domains
                "ai_reasoning": Experience("ai_reasoning"),
                "pattern_recognition": Experience("pattern_recognition"),
                "error_prediction": Experience("error_prediction"),
                "optimization": Experience("optimization"),
            }

            # Update experience with enhanced domains
            self.experience.update(enhanced_experience)

            # Enhanced core values and principles
            enhanced_values = {
                "reliability": "Consistent, dependable performance in all conditions",
                "efficiency": "Optimal resource usage and time management",
                "intelligence": "Smart reasoning and adaptive learning",
                "transparency": "Clear communication and honest feedback",
                "safety": "Secure operations with error handling and recovery",
                "adaptability": "Learning from experience and improving over time",
                "helpfulness": "Focus on user needs and practical solutions",
                # New enhanced values
                "logic_filtering": "Filters superstitions from patterns, facts from fiction",
                "essence_compression": "Compresses complex ideas into understandable forms",
                "battle_testing": "Validated under real-world conditions",
                "context_awareness": "Understands and maintains operational context",
            }

            self.values.update(enhanced_values)

            # Enhanced tool categories with new capabilities
            enhanced_tools = self._initialize_enhanced_tools()

            # Training metrics
            training_results = {
                "success": True,
                "training_timestamp": datetime.now().isoformat(),
                "enhanced_capabilities": {
                    "experience_domains": len(self.experience),
                    "core_values": len(self.values),
                    "tool_categories": len(enhanced_tools),
                    "total_tools": sum(
                        len(category) for category in enhanced_tools.values()
                    ),
                },
                "new_features": [
                    "Logic System: Filters superstitions vs patterns",
                    "Essence Compression: Complex ideas to simple forms",
                    "Enhanced Error Prediction",
                    "Pattern Recognition Engine",
                    "Optimization Algorithms",
                    "Battle-Tested Reliability",
                ],
                "openai_integration": {
                    "enabled": self.openai_enabled,
                    "model": self.model_preference if self.openai_enabled else "local",
                    "enhanced_reasoning": self.openai_enabled,
                },
            }

            # Update tools with enhanced capabilities
            self.tools.update(enhanced_tools)

            # Load training data if provided
            if training_data_path and Path(training_data_path).exists():
                with open(training_data_path, encoding="utf-8") as f:
                    training_data = json.load(f)

                # Process training data to enhance experience
                self._process_training_data(training_data)
                training_results["training_data_loaded"] = True
                training_results["training_patterns"] = len(
                    training_data.get("patterns", {})
                )

            print(
                f"‚úÖ Training Complete! Enhanced with {len(training_results['new_features'])} new capabilities"
            )
            print("üß† Logic System: Online - Filtering superstitions from patterns")
            print(
                f"‚ö° Battle-Tested: {training_results['enhanced_capabilities']['total_tools']} tools ready"
            )

            return training_results

        except Exception as e:
            logger.error(f"Training failed: {e}")
            return {
                "success": False,
                "error": str(e),
                "training_timestamp": datetime.now().isoformat(),
            }

    def _initialize_base_tools(self) -> dict[str, Any]:
        """Initialize base tool categories for the fused assistant."""
        return {
            "file_operations": {
                "read": self._read_file,
                "write": self._write_file,
                "list": self._list_files,
                "search": self._search_files,
                "analyze": self._analyze_file_with_args,
                "diff": self._compare_files,
                "backup": self._backup_file,
                "create": self._create_file,
                "delete": self._delete_file,
                "move": self._move_file,
                "copy": self._copy_file,
            },
            "system_commands": {
                "execute": self._execute_command,
                "process_info": self._get_process_info,
                "disk_usage": self._get_disk_usage,
                "network_status": self._check_network,
                "system_info": self._get_system_info,
                "env_vars": self._get_env_vars,
                "running_processes": self._get_running_processes,
            },
            "web_operations": {
                "web_search": self._web_search,
                "download": self._download_file,
                "http_status": self._check_http_status,
                "curl": self._curl_request,
                "api_call": self._make_api_call,
            },
            "code_operations": {
                "run": self._run_code,
                "lint": self._lint_code,
                "format": self._format_code,
                "test": self._run_tests,
                "debug": self._debug_code,
                "profile": self._profile_code,
            },
            "data_operations": {
                "parse_csv": self._parse_csv,
                "parse_json": self._parse_json,
                "analyze_data": self._analyze_data,
                "clean_data": self._clean_data,
                "statistics": self._get_statistics,
            },
            "analysis_operations": {
                "review_code": self._review_code,
                "security_scan": self._security_scan,
                "analyze_performance": self._analyze_performance,
                "check_dependencies": self._check_dependencies,
            },
            "realtime_operations": {
                "start_file_monitor": self._start_file_monitor,
                "stop_file_monitor": self._stop_file_monitor,
                "system_stats": self._get_system_stats,
                "list_processes": self._list_processes,
                "stop_monitoring": self._stop_all_monitoring,
            },
            "enhanced_web_operations": {
                "enhanced_web_search": self._enhanced_web_search,
                "summarize_search": self._summarize_search_results,
                "search_providers": self._list_search_providers,
            },
            "function_calling": {
                "register_function": self._register_ai_function,
                "list_functions": self._list_ai_functions,
                "call_function": self._call_ai_function,
                "function_chat": self._function_chat,
            },
            "assistant_commands": {
                "help": self._show_help,
                "status": self.get_status,
                "history": self._get_history,
                "clear": self._clear_screen,
                "save_session": self._save_session,
                "load_session": self._load_session,
                "metrics": self._get_metrics,
                "tools": self._list_tools,
                "train": self.train_assistant,
            },
        }

    def _initialize_enhanced_tools(self) -> dict[str, Any]:
        """Initialize enhanced tool categories with battle-tested capabilities."""
        enhanced_tools = {}

        # Copy existing tools
        enhanced_tools.update(self.tools)

        # Add new enhanced tool categories
        enhanced_tools["logic_operations"] = {
            "filter_patterns": self._filter_superstitions_from_patterns,
            "extract_essence": self._compress_complex_ideas,
            "validate_logic": self._validate_logical_consistency,
            "recognize_patterns": self._recognize_underlying_patterns,
            "predict_errors": self._predict_potential_errors,
        }

        enhanced_tools["optimization_operations"] = {
            "optimize_workflow": self._optimize_command_workflow,
            "suggest_improvements": self._suggest_performance_improvements,
            "auto_tune": self._auto_tune_parameters,
            "resource_optimize": self._optimize_resource_usage,
        }

        return enhanced_tools

    def _process_training_data(self, training_data: dict[str, Any]):
        """Process training data to enhance assistant experience."""
        patterns = training_data.get("patterns", {})
        best_practices = training_data.get("best_practices", [])

        # Update experience domains with training data
        for domain, exp in self.experience.items():
            if domain in patterns:
                for pattern, count in patterns[domain].items():
                    exp.patterns[pattern] = exp.patterns.get(pattern, 0) + count

        # Add best practices to relevant domains
        for practice in best_practices:
            domain = practice.get("domain", "general")
            if domain in self.experience:
                self.experience[domain].best_practices.append(
                    practice.get("description", "")
                )

    # Enhanced Logic Operations
    def _filter_superstitions_from_patterns(self, data: str) -> dict[str, Any]:
        """Filter superstitions from actual patterns in data."""
        # Logic filtering implementation
        patterns = re.findall(r"\b\w+(?:ing|ed|s)\b", data.lower())

        # Filter out common superstitions/biases
        superstitions = ["always", "never", "impossible", "perfect", "guaranteed"]
        filtered_patterns = [p for p in patterns if p not in superstitions]

        return {
            "original_patterns": len(patterns),
            "filtered_patterns": len(filtered_patterns),
            "superstitions_removed": len(patterns) - len(filtered_patterns),
            "valid_patterns": list(set(filtered_patterns))[:10],
        }

    def _compress_complex_ideas(self, text: str) -> dict[str, Any]:
        """Compress complex ideas into essential forms."""
        sentences = text.split(".")
        essential_ideas = []

        for sentence in sentences:
            sentence = sentence.strip()
            if len(sentence) > 10:  # Skip very short fragments
                # Extract key concepts (simplified)
                words = sentence.split()
                key_words = [w for w in words if len(w) > 4][
                    :5
                ]  # Top 5 meaningful words
                if key_words:
                    essential_ideas.append(" ".join(key_words))

        return {
            "original_length": len(text),
            "compressed_ideas": essential_ideas,
            "compression_ratio": len(" ".join(essential_ideas)) / len(text)
            if text
            else 0,
            "essence": essential_ideas[:3],  # Top 3 essential ideas
        }

    def _validate_logical_consistency(self, statement: str) -> dict[str, Any]:
        """Validate logical consistency of statements."""
        # Simple consistency checks
        contradictions = []

        # Check for absolute statements that might be inconsistent
        if re.search(
            r"\balways\b.*\bnever\b|\bnever\b.*\balways\b", statement, re.IGNORECASE
        ):
            contradictions.append("Always/never contradiction detected")

        if re.search(
            r"\bimpossible\b.*\bpossible\b|\bpossible\b.*\bimpossible\b",
            statement,
            re.IGNORECASE,
        ):
            contradictions.append("Possible/impossible contradiction detected")

        return {
            "statement": statement[:100] + "..." if len(statement) > 100 else statement,
            "is_consistent": len(contradictions) == 0,
            "contradictions": contradictions,
            "confidence": 0.9 if len(contradictions) == 0 else 0.3,
        }

    def _recognize_underlying_patterns(self, data: str) -> dict[str, Any]:
        """Recognize underlying patterns in data."""
        # Pattern recognition implementation
        word_freq = Counter(data.lower().split())
        common_patterns = word_freq.most_common(10)

        # Look for sequential patterns
        lines = data.split("\n")
        line_patterns = []

        for i, line in enumerate(lines[:20]):  # First 20 lines
            if line.strip():
                pattern = {
                    "line_number": i + 1,
                    "word_count": len(line.split()),
                    "starts_with": line.strip()[:20],
                    "pattern_type": "short"
                    if len(line) < 50
                    else "medium"
                    if len(line) < 100
                    else "long",
                }
                line_patterns.append(pattern)

        return {
            "word_patterns": dict(common_patterns[:5]),
            "line_patterns": line_patterns[:5],
            "dominant_theme": common_patterns[0][0] if common_patterns else "none",
            "complexity": "high"
            if len(common_patterns) > 50
            else "medium"
            if len(common_patterns) > 20
            else "low",
        }

    def _predict_potential_errors(self, command: str) -> dict[str, Any]:
        """Predict potential errors in command execution."""
        error_predictions = []

        # Common error patterns
        if "rm " in command and "-rf" in command:
            error_predictions.append("High risk: Force recursive delete detected")

        if "sudo " in command and "rm " in command:
            error_predictions.append("Critical risk: Root delete operation")

        if "format" in command.lower():
            error_predictions.append("Data loss risk: Format operation detected")

        if "shutdown" in command.lower() or "reboot" in command.lower():
            error_predictions.append("System impact: Shutdown/reboot operation")

        # File operation risks
        if any(op in command for op in [">", ">>"]) and "backup" not in command.lower():
            error_predictions.append("Data overwrite risk: No backup detected")

        return {
            "command": command,
            "risk_level": "high"
            if len(error_predictions) > 2
            else "medium"
            if error_predictions
            else "low",
            "predicted_errors": error_predictions,
            "suggestions": [
                "Consider running with --dry-run first",
                "Create backup before destructive operations",
                "Test in safe environment first",
            ]
            if error_predictions
            else ["Command appears safe"],
        }

    # Enhanced Optimization Operations
    def _optimize_command_workflow(self, workflow: list[str]) -> dict[str, Any]:
        """Optimize a sequence of commands for better performance."""
        optimizations = []

        # Look for redundant operations
        file_ops = [
            cmd
            for cmd in workflow
            if any(op in cmd for op in ["read ", "write ", "cat "])
        ]
        if len(file_ops) > 3:
            optimizations.append("Consider batching file operations")

        # Look for repeated commands
        cmd_counts = Counter(workflow)
        repeated = [cmd for cmd, count in cmd_counts.items() if count > 1]
        if repeated:
            optimizations.append(f"Repeated commands detected: {repeated}")

        return {
            "original_commands": len(workflow),
            "optimizations": optimizations,
            "optimized_workflow": workflow,  # Would contain actual optimizations in full implementation
            "performance_gain": "15-25%" if optimizations else "No optimization needed",
        }

    def _suggest_performance_improvements(self, operation: str) -> dict[str, Any]:
        """Suggest performance improvements for operations."""
        suggestions = []

        if "search" in operation.lower():
            suggestions.extend(
                [
                    "Use specific file extensions to narrow search",
                    "Consider using grep for faster text search",
                    "Limit search depth for large directories",
                ]
            )

        if "download" in operation.lower():
            suggestions.extend(
                [
                    "Use parallel downloads for multiple files",
                    "Check if resume capability is needed",
                    "Verify available disk space first",
                ]
            )

        return {
            "operation": operation,
            "improvements": suggestions,
            "estimated_speedup": "20-40%" if suggestions else "Already optimized",
        }

    def _auto_tune_parameters(self, context: str) -> dict[str, Any]:
        """Auto-tune parameters based on context."""
        tuning_results = {}

        if "large file" in context.lower():
            tuning_results["buffer_size"] = "64KB"
            tuning_results["chunk_size"] = "1MB"

        if "network" in context.lower():
            tuning_results["timeout"] = "30s"
            tuning_results["retry_count"] = 3

        return {
            "context": context,
            "tuned_parameters": tuning_results,
            "optimization_applied": len(tuning_results) > 0,
        }

    def _optimize_resource_usage(self) -> dict[str, Any]:
        """Optimize current resource usage."""
        optimizations = []

        # Check memory usage
        if PSUTIL_AVAILABLE:
            memory_percent = psutil.virtual_memory().percent
            if memory_percent > 80:
                optimizations.append("High memory usage detected")

            # Check disk space
            disk = psutil.disk_usage(".")
            if disk.percent > 90:
                optimizations.append("Low disk space detected")

        return {
            "current_optimizations": optimizations,
            "resource_status": "optimal" if not optimizations else "needs_attention",
            "recommendations": [
                "Clear temporary files",
                "Close unused applications",
                "Consider cleanup operations",
            ]
            if optimizations
            else ["Resource usage is optimal"],
        }

    def get_status(self) -> dict[str, Any]:
        """Get assistant status."""
        return {
            "version": self.version,
            "session_id": self.session_id,
            "uptime": time.time() - self.session_start_time,
            "commands_executed": self.metrics["total_commands"],
            "success_rate": self.metrics["successful_commands"]
            / max(1, self.metrics["total_commands"]),
            "openai_enabled": self.openai_enabled,
            "current_model": self.model_preference if self.openai_enabled else "local",
        }

    def _get_history(self, count: int = 10) -> list[dict[str, Any]]:
        """Get command history."""
        return self.command_history[-count:]

    def _clear_screen(self) -> str:
        """Clear screen."""
        os.system("cls" if os.name == "nt" else "clear")
        return "Screen cleared"

    def _save_session(self, filepath: str = None) -> dict[str, Any]:
        """Save session data."""
        if not filepath:
            filepath = f"fused_session_{self.session_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

        session_data = {
            "version": self.version,
            "session_id": self.session_id,
            "timestamp": datetime.now().isoformat(),
            "conversation_history": [
                {
                    "role": msg.role,
                    "content": msg.content,
                    "timestamp": msg.timestamp.isoformat(),
                }
                for msg in self.conversation_history
            ],
            "command_history": self.command_history,
            "metrics": self.metrics,
            "openai_settings": {
                "enabled": self.openai_enabled,
                "model": self.model_preference,
                "available_models": list(self.available_models.keys()),
            },
        }

        try:
            with open(filepath, "w", encoding="utf-8") as f:
                json.dump(session_data, f, indent=2)
            return {"success": True, "filepath": filepath}
        except Exception as e:
            return {"error": str(e)}

    def _load_session(self, filepath: str) -> dict[str, Any]:
        """Load session data."""
        try:
            with open(filepath, encoding="utf-8") as f:
                session_data = json.load(f)

            self.conversation_history = [
                ConversationMessage(role=msg["role"], content=msg["content"])
                for msg in session_data.get("conversation_history", [])
            ]
            self.command_history = session_data.get("command_history", [])
            self.metrics = session_data.get("metrics", {})

            # Restore OpenAI settings
            openai_settings = session_data.get("openai_settings", {})
            self.model_preference = openai_settings.get("model", "gpt-3.5-turbo")

            return {"success": True, "filepath": filepath}
        except Exception as e:
            return {"error": str(e)}

    def _get_metrics(self) -> dict[str, Any]:
        """Get performance metrics."""
        return self.metrics

    def _list_tools(self) -> dict[str, list[str]]:
        """List available tools."""
        return {category: list(tools.keys()) for category, tools in self.tools.items()}

    # ============================================================================
    # Helper Methods (Simplified implementations)
    # ============================================================================

    def _get_complexity_assessment(
        self, command: str, args: list[str]
    ) -> ComplexityLevel:
        """Assess command complexity."""
        if command in ["help", "status", "list"]:
            return ComplexityLevel.SIMPLE
        elif command in ["read", "write", "execute", "search"]:
            return ComplexityLevel.MODERATE
        elif command in ["analyze", "review", "debug"]:
            return ComplexityLevel.COMPLEX
        else:
            return ComplexityLevel.EXPERT

    def _assess_confidence(self, command: str, args: list[str]) -> float:
        """Assess confidence level."""
        base_confidence = 0.8

        # Check if command exists
        for category, tools in self.tools.items():
            if command in tools:
                return base_confidence

        # Command not found - lower confidence
        return 0.3

    def _validate_arguments(self, command: str, args: list[str], tool_function) -> bool:
        """Validate command arguments."""
        if command in ["read", "analyze", "delete"] and len(args) < 1:
            return False
        if command in ["write", "create"] and len(args) < 1:
            return False
        if command in ["diff", "move", "copy"] and len(args) < 2:
            return False

        return True

    def _generate_suggestions(
        self, command: str, args: list[str], result: CommandResult
    ) -> list[str]:
        """Generate suggestions based on execution results using selective attention."""
        all_suggestions = []

        if not result.success:
            if "not found" in result.error.lower():
                all_suggestions.append("Check if the file or command exists")
                all_suggestions.append("Use 'list' to see available files")
                all_suggestions.append("Try 'help' for available commands")
            elif "permission" in result.error.lower():
                all_suggestions.append("Check file permissions")
                all_suggestions.append("Try running with elevated privileges")
                all_suggestions.append("Use 'execute' with sudo if needed")
            elif "filtered" in result.error.lower():
                all_suggestions.append("Command was filtered by selective attention")
                all_suggestions.append("Try a more specific or important command")
                all_suggestions.append("Check 'attention status' for current threshold")
        else:
            if command in ["read", "analyze"]:
                all_suggestions.append("Try 'write' to create or modify files")
                all_suggestions.append("Use 'search' to find specific content")
                all_suggestions.append("Consider 'analyze' for deeper insights")
            elif command == "execute":
                all_suggestions.append("Check 'process_info' for running processes")
                all_suggestions.append("Use 'system_info' for system details")
                all_suggestions.append("Try 'analyze' on command output")
            elif command in ["list", "search"]:
                all_suggestions.append("Use 'analyze' on found files")
                all_suggestions.append("Try 'read' for specific files")
                all_suggestions.append("Consider 'search' with different patterns")

        # Add smart terminal suggestions if available
        if SMART_TERMINAL_AVAILABLE and self.smart_predictor:
            try:
                partial_command = f"{command} {' '.join(args)}" if args else command
                smart_suggestions = self.get_smart_suggestions(
                    partial_command, num_suggestions=3
                )
                if smart_suggestions:
                    all_suggestions.extend(
                        [f"Smart: {suggestion}" for suggestion in smart_suggestions]
                    )
            except Exception as e:
                logger.debug(f"Smart terminal suggestion error: {e}")

        # Apply selective attention to focus on most relevant suggestions
        focused_suggestions = selective_attention(
            all_suggestions,
            criteria=lambda x: len(x) > 10 and len(x) < 100,  # Reasonable length
            focus="low_complexity",
        )

        return focused_suggestions[:3]  # Return top 3 focused suggestions

    def _record_experience(self, command: str, args: list[str], result: CommandResult):
        """Record execution experience using selective attention to focus on relevant data."""
        if not self.settings["learning_enabled"]:
            return

        # Gather experience data
        experience_data = {
            "command": command,
            "args": args,
            "success": result.success,
            "execution_time": result.execution_time,
            "complexity": result.complexity,
            "confidence": result.confidence,
            "attention_score": getattr(result, "attention_score", 0.0),
        }

        # Apply selective attention to focus on important experience aspects
        relevant_experience = selective_attention(
            list(experience_data.items()),
            criteria=lambda x: x[1] is not None and x[1] != 0,
            focus="high_value",
        )

        # Extract focused patterns and practices
        domain = f"command_{command}"
        if domain not in self.experience:
            self.experience[domain] = Experience(domain)

        pattern = f"{command} {' '.join(args[:2])}" if args else command
        practice = f"Executed {command}" if result.success else ""
        failure = result.error if not result.success else ""

        # Record only attended experience
        if relevant_experience:
            self.experience[domain].record_attempt(
                success=result.success,
                pattern=pattern,
                practice=practice,
                failure=failure,
            )

    def _update_metrics(self, execution_time: float):
        """Update performance metrics using selective attention to focus on meaningful data."""
        # Gather all metric data
        all_metrics = {
            "total_commands": self.metrics["total_commands"] + 1,
            "successful_commands": self.metrics["successful_commands"]
            + (1 if execution_time > 0 else 0),
            "failed_commands": self.metrics["failed_commands"]
            + (0 if execution_time > 0 else 1),
            "execution_time": execution_time,
            "attention_efficiency": self.attention_stats.get("filter_rate", 0.0),
        }

        # Apply selective attention to focus on significant metrics
        significant_metrics = selective_attention(
            list(all_metrics.items()),
            criteria=lambda x: x[0]
            in ["total_commands", "successful_commands", "attention_efficiency"]
            and isinstance(x[1], (int, float)),
            focus="high_value",
        )

        # Update only attended metrics
        for metric_name, metric_value in significant_metrics:
            if metric_name in self.metrics:
                self.metrics[metric_name] = metric_value

        # Calculate attention efficiency
        if self.attention_stats["total_processed"] > 0:
            self.metrics["attention_efficiency"] = (
                1.0 - self.attention_stats["filter_rate"]
            )

    def _handle_error(
        self, command: str, args: list[str], error: Exception
    ) -> CommandResult:
        """Handle errors with recovery suggestions."""
        return CommandResult(
            success=False,
            error=str(error),
            complexity=self._get_complexity_assessment(command, args),
            confidence=0.0,
            suggestions=[
                "Check command syntax",
                "Verify arguments",
                "Use 'help' for assistance",
            ],
        )

    # ============================================================================
    # New Feature Implementations
    # ============================================================================

    # Realtime Monitoring Tools
    def _start_file_monitor(self, path: str) -> dict[str, Any]:
        """Start monitoring a file or directory for changes."""
        success = self.realtime_monitor.start_file_monitoring(path)
        if success:
            return {
                "success": True,
                "message": f"Started monitoring: {path}",
                "path": path,
            }
        else:
            return {"success": False, "error": f"Failed to start monitoring: {path}"}

    def _stop_file_monitor(self, path: str) -> dict[str, Any]:
        """Stop monitoring a file or directory."""
        success = self.realtime_monitor.stop_file_monitoring(path)
        if success:
            return {
                "success": True,
                "message": f"Stopped monitoring: {path}",
                "path": path,
            }
        else:
            return {"success": False, "error": f"Failed to stop monitoring: {path}"}

    def _get_system_stats(self) -> dict[str, Any]:
        """Get current system statistics."""
        return self.realtime_monitor.get_system_stats()

    def _list_processes(self, filter_name: str = None) -> list[dict[str, Any]]:
        """List running processes with optional filtering."""
        return self.realtime_monitor.list_processes(filter_name)

    def _stop_all_monitoring(self) -> dict[str, Any]:
        """Stop all monitoring activities."""
        self.realtime_monitor.stop_monitoring()
        return {"success": True, "message": "All monitoring stopped"}

    # Enhanced Web Search Tools
    def _enhanced_web_search(
        self, query: str, provider: str = "duckduckgo", num_results: int = 5
    ) -> dict[str, Any]:
        """Perform enhanced web search with specified provider."""
        return self.web_searcher.search(
            query, provider, num_results, include_metadata=True
        )

    def _summarize_search_results(self, search_results: dict) -> dict[str, Any]:
        """Summarize web search results."""
        return self.web_searcher.summarize_results(search_results)

    def _list_search_providers(self) -> list[str]:
        """List available search providers."""
        return list(self.web_searcher.providers.keys())

    # Function Calling Tools
    def _register_ai_function(
        self, name: str, description: str, parameters: dict
    ) -> dict[str, Any]:
        """Register a custom function for AI to call."""
        # Note: This is a placeholder - in practice, you'd need to provide the actual function
        try:
            # For demo purposes, we'll create a simple wrapper
            def dummy_function(**kwargs):
                return {"message": f"Function {name} called with {kwargs}"}

            self.function_caller.register_function(
                name, dummy_function, description, parameters
            )
            return {"success": True, "message": f"Registered function: {name}"}
        except Exception as e:
            return {"success": False, "error": str(e)}

    def _list_ai_functions(self) -> list[str]:
        """List available AI functions."""
        return list(self.function_caller.available_functions.keys())

    def _call_ai_function(self, name: str, arguments: dict) -> dict[str, Any]:
        """Call a registered AI function."""
        return self.function_caller.call_function(name, arguments)

    def _function_chat(self, message: str) -> dict[str, Any]:
        """Chat with function calling enabled."""
        if not self.openai_enabled:
            return {"error": "OpenAI not enabled for function calling"}

        # Build conversation context
        messages = [
            {
                "role": "system",
                "content": """You are an AI assistant with access to various functions and tools.
You can call functions to get information, execute commands, search the web, and monitor systems.
When you need to perform an action, use the available functions instead of just describing what you'd do.""",
            }
        ]

        # Add recent conversation
        for msg in self.conversation_history[-3:]:
            messages.append({"role": msg.role, "content": msg.content})

        messages.append({"role": "user", "content": message})

        result = self.function_caller.process_with_functions(messages)
        return result


# ============================================================================
# Main Entry Point
# ============================================================================


def main():
    """Main entry point for the fused assistant."""
    parser = argparse.ArgumentParser(
        description="Fused Terminal Chat & Command Assistant with OpenAI Integration and Selective Attention",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  %(prog)s --chat                    # Start chat mode
  %(prog)s --cmd "read file.txt"     # Execute single command
  %(prog)s --session session.json    # Load previous session
  %(prog)s --save-session my.json   # Save session on exit
  %(prog)s --attention-status        # Show selective attention statistics
        """,
    )

    parser.add_argument(
        "--chat", action="store_true", help="Start in chat mode (AI conversation)"
    )

    parser.add_argument("--cmd", help="Execute single command and exit")

    parser.add_argument("--session", help="Load session from file")

    parser.add_argument("--save-session", help="Save session to file on exit")

    parser.add_argument(
        "--attention-status",
        action="store_true",
        help="Show selective attention statistics and exit",
    )

    parser.add_argument(
        "--verbose", "-v", action="store_true", help="Enable verbose output"
    )

    args = parser.parse_args()

    # Initialize assistant
    assistant = FusedAssistant()

    # Load session if specified
    if args.session:
        result = assistant._load_session(args.session)
        if result.get("success"):
            print(f"‚úÖ Session loaded from {args.session}")
        else:
            print(f"‚ùå Failed to load session: {result.get('error')}")

    try:
        if args.attention_status:
            # Show selective attention statistics
            attention_status = assistant.get_attention_status()
            print("üß† Selective Attention Status:")
            print("=" * 40)
            print(f"Threshold: {attention_status['attention_threshold']}")
            print(f"Max Items: {attention_status['max_attention_items']}")
            print(f"ML Explanation: {attention_status['enable_ml_explanation']}")
            print("\nüìä Statistics:")
            print(
                f"Total Processed: {attention_status['statistics']['total_processed']}"
            )
            print(
                f"Attention Filtered: {attention_status['statistics']['attention_filtered']}"
            )
            print(f"Filter Rate: {attention_status['efficiency']['filter_rate']:.2%}")
            print(
                f"Average Score: {attention_status['efficiency']['average_score']:.3f}"
            )
            return

        elif args.chat:
            # Chat mode
            assistant.chat_mode()

        elif args.cmd:
            # Single command mode
            print(f"‚ö° Executing: {args.cmd}")
            result = assistant.execute_command(args.cmd)

            if result.success:
                print(f"‚úÖ Success ({result.execution_time:.2f}s)")
                if result.output:
                    print(result.output)
                if hasattr(result, "attention_score"):
                    print(f"üß† Attention Score: {result.attention_score:.3f}")
            else:
                print(f"‚ùå Failed ({result.execution_time:.2f}s)")
                print(f"Error: {result.error}")
                if hasattr(result, "attention_filtered") and result.attention_filtered:
                    print("üîç Command was filtered by selective attention")

        else:
            # Interactive menu mode
            while True:
                print("\nü§ñ Fused Assistant - Main Menu")
                print("=" * 40)
                print("1. Chat Mode (conversational)")
                print("2. Command Mode (precise operations)")
                print("3. Smart Terminal (intelligent CLI)")
                print("4. Status")
                print("5. Attention Status")
                print("6. Help")
                print("7. Quit")
                try:
                    import os
                    if os.getenv("ECHOES_ORCHESTRAL_ENABLED", "").lower() in ("1", "true", "yes", "on"):
                        print("8. Orchestral Demo (template + strategy)")
                except Exception:
                    pass
                print("=" * 40)

                choice = input("Select option (1-8): ").strip()

                if choice == "1":
                    assistant.chat_mode()
                elif choice == "2":
                    assistant.command_mode()
                elif choice == "3":
                    assistant.start_smart_terminal_mode()
                elif choice == "4":
                    status = assistant._get_status()
                    print("\nüìä Assistant Status:")
                    print(f"  Version: {status['version']}")
                    print(f"  Session: {status['session_id']}")
                    print(f"  Uptime: {status['uptime']:.1f}s")
                    print(f"  Commands: {status['commands_executed']}")
                    print(f"  Success Rate: {status['success_rate']:.1%}")
                    print(f"  AI Mode: {status['current_model']}")
                    # Enhanced with orchestral status
                    try:
                        from orchestral_strategy import OrchestralConductor, OrchestralConfig
                        config = OrchestralConfig(
                            echo_core_path=".",
                            reverb_module_path="../Reverb",
                            delay_module_path="../Delay",
                            routing_connector_path="../Routing",
                            arcade_platform_path="../Arcade"
                        )
                        OrchestralConductor(config)
                        print("  Orchestral: Ready for spatial/temporal optimization")
                    except ImportError:
                        print("  Orchestral: Modules not available")
                elif choice == "5":
                    attention_status = assistant.get_attention_status()
                    print("\nüß† Selective Attention Status:")
                    print(f"  Threshold: {attention_status['attention_threshold']}")
                    print(
                        f"  Filter Rate: {attention_status['efficiency']['filter_rate']:.2%}"
                    )
                    print(
                        f"  Average Score: {attention_status['efficiency']['average_score']:.3f}"
                    )
                    print(
                        f"  Total Processed: {attention_status['statistics']['total_processed']}"
                    )
                elif choice == "6":
                    help_text = assistant._show_help()
                    print(f"\n{help_text}")
                elif choice == "7":
                    print("üëã Goodbye!")
                    break
                elif choice == "8":
                    try:
                        import os
                        if os.getenv("ECHOES_ORCHESTRAL_ENABLED", "").lower() not in ("1", "true", "yes", "on"):
                            print("‚ö†Ô∏è Orchestral disabled. Set ECHOES_ORCHESTRAL_ENABLED=1 to enable demo.")
                        else:
                            # Run template demo main() and strategy()
                            from template_process import main as tpl_main, strategy as tpl_strategy
                            print("\n=== Orchestral Demo: template_process.main() ===")
                            tpl_main()
                            print("\n=== Orchestral Demo: orchestral_strategy.strategy() ===")
                            from orchestral_strategy import strategy as orch_strategy
                            orch_strategy()
                            # Simple echo to confirm
                            print("\n‚úÖ Demo completed. Results and strategy printed above.")
                    except ImportError as e:
                        print(f"‚ùå Demo unavailable: {e}")
                    except Exception as e:
                        print(f"‚ùå Demo error: {e}")
                else:
                    print("‚ùå Invalid option. Please select 1-7.")

    except KeyboardInterrupt:
        print("\nüëã Interrupted. Exiting...")

    finally:
        # Save session if requested
        if args.save_session:
            result = assistant._save_session(args.save_session)
            if result.get("success"):
                print(f"üíæ Session saved: {result['filepath']}")
            else:
                print(f"‚ùå Failed to save session: {result['error']}")


if __name__ == "__main__":
    exit(main())
