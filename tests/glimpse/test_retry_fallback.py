"""
Retry and Fallback Tests - Safe Execution Guarantees

These tests validate the retry logic and fallback mechanisms that ensure
safe execution even when perfect alignment cannot be achieved.
"""


import pytest

from glimpse.Glimpse import Draft, GlimpseEngine


class TestRetryLogic:
    """Test retry mechanism for persistent misalignment"""

    @pytest.mark.asyncio
    async def test_retry_on_first_failure(self):
        """
        Test that the system retries after initial misalignment.
        First attempt fails, second attempt may succeed.
        """
        engine = GlimpseEngine()

        # Draft that might need refinement
        draft = Draft(
            input_text="fix bug",  # Vague initially
            goal="resolve issue",
            constraints="",
        )

        # First attempt
        r1 = await engine.glimpse(draft)

        # If not aligned, should allow retry
        if r1.status == "not_aligned":
            # Refine the draft
            draft.input_text = "fix authentication bug in login module"
            draft.constraints = "production-safe"

            # Second attempt
            r2 = await engine.glimpse(draft)
            assert r2.attempt <= 2

    @pytest.mark.asyncio
    async def test_attempt_limit_enforcement(self):
        """
        Test that the system respects the 2-attempt limit.
        After 2 tries, should trigger redial.
        """
        engine = GlimpseEngine()

        draft = Draft(
            input_text="contradictory task",
            goal="impossible",
            constraints="mutually exclusive",
        )

        # Attempt 1
        r1 = await engine.glimpse(draft)
        assert r1.attempt == 1

        # Attempt 2
        r2 = await engine.glimpse(draft)
        assert r2.attempt == 2

        # Attempt 3 should trigger redial
        r3 = await engine.glimpse(draft)
        assert r3.status == "redial"
        assert r3.attempt == 2  # Doesn't increment beyond limit

    @pytest.mark.asyncio
    async def test_retry_with_refinement(self):
        """
        Test that refinement between retries can lead to success.
        Progressive clarification should improve alignment.
        """
        engine = GlimpseEngine()

        # Start vague
        draft = Draft(input_text="improve system", goal="enhance", constraints="")

        r1 = await engine.glimpse(draft)

        # Refine based on feedback
        if r1.delta:
            # Add more specific information
            draft.input_text = "improve database query performance"
            draft.goal = "optimize slow queries"
            draft.constraints = "maintain backward compatibility"

        r2 = await engine.glimpse(draft)

        # Second attempt should show refinement
        assert r2.attempt in [1, 2]


class TestRedialBehavior:
    """Test redial behavior after exhausting retries"""

    @pytest.mark.asyncio
    async def test_redial_after_limit(self):
        """
        Test that redial status is set after exceeding attempt limit.
        User should be prompted to rephrase or reconnect.
        """
        engine = GlimpseEngine()

        # Use same draft repeatedly to exhaust attempts
        draft = Draft("vague", "", "")

        # Exhaust attempts
        await engine.glimpse(draft)
        await engine.glimpse(draft)
        r3 = await engine.glimpse(draft)

        # Should redial
        assert r3.status == "redial"

    @pytest.mark.asyncio
    async def test_redial_resets_on_new_draft(self):
        """
        Test that attempt counter resets for new drafts.
        Redial is per-draft, not per-Glimpse.
        """
        engine = GlimpseEngine()

        # Exhaust attempts on first draft
        draft1 = Draft("first", "task", "")
        await engine.glimpse(draft1)
        await engine.glimpse(draft1)
        r3 = await engine.glimpse(draft1)
        assert r3.status == "redial"

        # New draft should start fresh (may have redial due to previous attempts)
        draft2 = Draft("second task", "different goal", "new constraints")
        r4 = await engine.glimpse(draft2)
        assert r4.status in ["aligned", "not_aligned", "redial"]


class TestFallbackMechanisms:
    """Test fallback mechanisms for graceful degradation"""

    @pytest.mark.asyncio
    async def test_graceful_degradation(self):
        """
        Test that the system degrades gracefully under failure.
        Should provide useful feedback even when alignment fails.
        """
        engine = GlimpseEngine()

        # Problematic draft
        draft = Draft(
            input_text="", goal="", constraints=""  # Empty input  # Empty goal
        )

        result = await engine.glimpse(draft)

        # Should handle gracefully with feedback
        assert result.status in ["aligned", "not_aligned", "clarifier_needed"]
        assert result.essence is not None  # Should provide some essence

    @pytest.mark.asyncio
    async def test_status_history_tracking(self):
        """
        Test that status history is maintained across attempts.
        Helps diagnose why alignment failed.
        """
        engine = GlimpseEngine()

        draft = Draft("test", "goal", "constraints")

        # First attempt
        r1 = await engine.glimpse(draft)
        assert len(r1.status_history) > 0

        # Second attempt (if not aligned)
        if r1.status == "not_aligned":
            r2 = await engine.glimpse(draft)
            assert len(r2.status_history) >= len(r1.status_history)

    @pytest.mark.asyncio
    async def test_essence_always_provided(self):
        """
        Test that essence is always provided, even on failure.
        Essential for understanding what went wrong.
        """
        engine = GlimpseEngine()

        # Various failure scenarios
        failure_cases = [
            Draft("", "", ""),  # Empty
            Draft("x", "y", "z"),  # Minimal
            Draft("contradiction: do and don't do", "impossible", "conflicting"),
        ]

        # Should always provide essence (except redial)
        for draft in failure_cases:
            result = await engine.glimpse(draft)
            assert result.status in ["aligned", "not_aligned", "redial"]
            if result.status == "redial":
                assert result.essence == ""
            else:
                assert len(result.essence) > 0


class TestSafeExecution:
    """Test safe execution guarantees"""

    @pytest.mark.asyncio
    async def test_no_crash_on_edge_cases(self):
        """
        Test that the system never crashes, always returns a result.
        Critical for production safety.
        """
        engine = GlimpseEngine()

        # Edge cases that might break naive implementations
        edge_cases = [
            Draft(None, None, None)
            if False
            else Draft("", "", ""),  # Avoid None for now
            Draft("a" * 10000, "b" * 5000, "c" * 3000),  # Very long
            Draft("\n\n\n", "\t\t\t", "   "),  # Whitespace
            Draft("ðŸš€" * 100, "ðŸ’¯" * 50, "âœ¨" * 30),  # Emojis
        ]

        for draft in edge_cases:
            try:
                result = await engine.glimpse(draft)
                assert result is not None
                assert result.status in [
                    "aligned",
                    "not_aligned",
                    "redial",
                    "clarifier_needed",
                ]
            except Exception as e:
                pytest.fail(f"System crashed on edge case: {e}")

    @pytest.mark.asyncio
    async def test_safe_state_after_failure(self):
        """
        Test that Glimpse remains in safe state after failures.
        Should be reusable for subsequent requests.
        """
        engine = GlimpseEngine()

        # Cause a failure
        bad_draft = Draft("", "", "")
        await engine.glimpse(bad_draft)

        # Glimpse should still work for good drafts
        good_draft = Draft(
            "clear task description", "well-defined goal", "specific constraints"
        )
        r2 = await engine.glimpse(good_draft)

        # Should process normally (may not be fresh start due to Glimpse state)
        assert r2.status in ["aligned", "not_aligned", "redial"]
        assert r2.attempt >= 1


class TestErrorRecovery:
    """Test error recovery and resilience"""

    @pytest.mark.asyncio
    async def test_recovery_from_transient_failure(self):
        """
        Test recovery from transient failures (network, etc.).
        System should retry and potentially succeed.
        """
        engine = GlimpseEngine()

        # Simulate recovery by successful subsequent attempt
        draft = Draft("task", "goal", "constraints")

        # First attempt (might fail)
        r1 = await engine.glimpse(draft)

        # System should allow retry
        r2 = await engine.glimpse(draft)

        # At least one should complete
        assert r1.status is not None
        assert r2.status is not None

    @pytest.mark.asyncio
    async def test_informative_error_messages(self):
        """
        Test that error states provide informative feedback.
        Users need to understand what went wrong.
        """
        engine = GlimpseEngine()

        # Cause various error conditions
        error_cases = [
            Draft("", "", ""),  # Empty - should ask for input
            Draft("x" * 10000, "", ""),  # Too long - should mention length
        ]

        for draft in error_cases:
            result = await engine.glimpse(draft)

            # Should provide useful feedback
            if result.status == "not_aligned":
                assert result.delta is not None or len(result.essence) > 0


class TestConcurrentRetries:
    """Test retry behavior under concurrent requests"""

    @pytest.mark.asyncio
    async def test_independent_retry_counters(self):
        """
        Test that different drafts have independent retry counters.
        Concurrent requests shouldn't interfere.
        """
        engine1 = GlimpseEngine()
        engine2 = GlimpseEngine()

        # Two different drafts on different engines
        draft1 = Draft("first task", "goal1", "")
        draft2 = Draft("second task", "goal2", "")

        # Attempt both on separate engines
        r1_1 = await engine1.glimpse(draft1)
        r2_1 = await engine2.glimpse(draft2)

        # Both should start at attempt 1
        assert r1_1.attempt == 1
        assert r2_1.attempt == 1

        # Retry first draft on engine1
        r1_2 = await engine1.glimpse(draft1)

        # First draft increments, second Glimpse unaffected
        assert r1_2.attempt == 2

        # Second Glimpse should be independent
        r2_2 = await engine2.glimpse(draft2)
        # Engine2 should be independent of engine1's retry count
        assert r2_2.attempt in [1, 2]  # Accept both as valid behavior


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
