# Echoes Assistant V2 Core - Full Coverage Test Suite

## ğŸ¯ Overview

This comprehensive test suite validates the complete functionality of `assistant_v2_core.py` through the Echoes API endpoints. It tests the OpenAI API migration between Chat Completions and Responses APIs, ensuring all features work correctly.

## ğŸ§ª What Gets Tested

### **Core Migration Features**
- âœ… **Responses API Implementation**: Tool calling, streaming, message handling
- âœ… **Chat Completions Fallback**: Backward compatibility and error recovery
- âœ… **Dual API Support**: Seamless switching based on configuration
- âœ… **Streaming Responses**: Both APIs with proper chunk handling

### **Advanced Features**
- âœ… **Tool Calling Loop**: Multi-step tool execution with state management
- âœ… **Agent Actions**: Quantum state, inventory, ROI analysis
- âœ… **Workflow Orchestration**: Business initiative triage and execution
- âœ… **RAG Integration**: Knowledge search and retrieval
- âœ… **Error Handling**: Validation, API errors, fallbacks

### **Performance & Reliability**
- âœ… **Response Time Monitoring**: Latency tracking and optimization
- âœ… **Token Usage Tracking**: API cost monitoring
- âœ… **Error Resilience**: Circuit breaker patterns and recovery
- âœ… **Concurrent Load Testing**: Multi-worker execution

## ğŸš€ Quick Start

### **Option 1: Automated Setup (Windows)**
```batch
# Run the automated test setup
run_full_tests.bat
```

This will:
- Create/update virtual environment
- Install dependencies
- Start the API server
- Run all tests automatically
- Generate comprehensive reports

### **Option 2: Manual Setup**

1. **Start the API Server:**
```bash
# Terminal 1 - Start API server
uvicorn api.main:app --reload --port 8000
```

2. **Run Tests:**
```bash
# Terminal 2 - Run test suite
python full_coverage_test_runner.py --check-api --workers 4
```

## ğŸ“‹ Test Categories

### **API Migration Tests (4 tests)**
- `responses_api_basic_chat` - Basic chat with Responses API
- `responses_api_streaming` - Streaming responses
- `responses_api_tool_calling` - Tool execution with Responses API
- `chat_completions_fallback` - Fallback to Chat Completions

### **Advanced Features (4 tests)**
- `responses_api_quantum_state` - Quantum state management
- `responses_api_workflow` - Business workflow orchestration
- `responses_api_knowledge_search` - RAG knowledge retrieval
- `responses_api_roi_analysis` - ROI calculation and analysis

### **Validation & Error Handling (4 tests)**
- `api_migration_validation` - Multi-turn conversations
- `error_handling_validation` - Input validation
- `performance_load_test` - Performance under load
- `fallback_to_chat_completions` - Error recovery mechanisms

## ğŸ“Š Output Files

The test suite generates multiple output formats:

- **`test_results_YYYYMMDD_HHMMSS.json`** - Complete test data with API responses
- **`performance_baseline.db`** - SQLite database for trend analysis
- **`test_suite.log`** - Detailed execution logs

## ğŸ® Usage Examples

### **Basic Test Run**
```bash
python full_coverage_test_runner.py
```

### **Custom Configuration**
```bash
# Use custom test config
python full_coverage_test_runner.py --config my_tests.json

# Different API endpoint
python full_coverage_test_runner.py --api-url https://my-api.com

# Higher parallelism
python full_coverage_test_runner.py --workers 8
```

### **API Health Check**
```bash
# Check API before running tests
python full_coverage_test_runner.py --check-api
```

### **Performance Analysis**
```bash
# Analyze trends (requires historical data)
python full_coverage_test_runner.py --trend-analysis --days 7
```

## ğŸ”§ Configuration

### **Test Configuration File** (`full_coverage_test_config.json`)

```json
{
  "tests": [
    {
      "name": "responses_api_basic_chat",
      "prompt": "Hello, how are you today?",
      "expected_outcome": "success",
      "timeout": 30,
      "tags": ["responses_api", "basic"],
      "metadata": {
        "use_responses_api": true,
        "model": "gpt-4o-mini"
      }
    }
  ],
  "settings": {
    "max_workers": 6,
    "test_categories": {
      "responses_api": ["responses_api_basic_chat"],
      "validation": ["error_handling_validation"]
    }
  }
}
```

### **Environment Variables**
```bash
export OPENAI_API_KEY="your-openai-api-key"
export ECHOES_API_URL="http://localhost:8000"
```

## ğŸ“ˆ Test Results Interpretation

### **Success Metrics**
- **Response Time**: < 30s for basic queries, < 60s for complex analysis
- **Success Rate**: > 95% for properly configured tests
- **Token Efficiency**: Optimized usage across both APIs
- **Error Recovery**: Automatic fallback when primary API fails

### **Performance Trends**
```bash
# View performance trends
python full_coverage_test_runner.py --trend-analysis --days 30
```

Shows:
- Average response time improvements
- Success rate stability
- Token usage optimization
- API reliability metrics

## ğŸ› Troubleshooting

### **API Server Issues**
```bash
# Check if server is running
curl http://localhost:8000/health

# View server logs
tail -f test_suite.log
```

### **Test Failures**
- Check `test_results_*.json` for detailed error messages
- Verify `OPENAI_API_KEY` is set correctly
- Ensure API endpoints are accessible
- Check firewall/proxy settings

### **Performance Issues**
- Reduce `--workers` if system resources are limited
- Increase `--timeout` for slower network connections
- Use `--mock` mode for offline testing

## ğŸ—ï¸ Architecture

### **Test Runner Components**
```
full_coverage_test_runner.py
â”œâ”€â”€ EchoesAPITester (main class)
â”‚   â”œâ”€â”€ test_chat_completion()     # Basic chat tests
â”‚   â”œâ”€â”€ test_agent_workflow()      # Workflow orchestration
â”‚   â”œâ”€â”€ test_validation_error()    # Error handling
â”‚   â””â”€â”€ run_full_test_suite()      # Parallel execution
â”œâ”€â”€ Test Configuration Loader
â”œâ”€â”€ Results Aggregation
â””â”€â”€ Performance Tracking
```

### **Integration Points**
- **API Endpoints**: `/api/ai/chat`, `/api/workflows/business-initiative`
- **Authentication**: Bearer token via `--api-key`
- **Configuration**: JSON-based test definitions
- **Parallelization**: ThreadPoolExecutor for concurrent testing

## ğŸ¯ Coverage Areas

### **assistant_v2_core.py Features Tested**
- âœ… Dual API architecture (Responses vs Chat Completions)
- âœ… Tool calling loop with multi-step execution
- âœ… Streaming response handling
- âœ… Error recovery and fallback mechanisms
- âœ… Model selection and routing
- âœ… Context management and conversation history
- âœ… Value system integration
- âœ… RAG knowledge retrieval
- âœ… Agent action execution
- âœ… Workflow orchestration
- âœ… Performance metrics collection

### **Migration Validation**
- âœ… API parameter mapping (messages â†’ input, etc.)
- âœ… Response format adaptation
- âœ… Tool call structure compatibility
- âœ… Streaming chunk processing
- âœ… Error handling consistency
- âœ… Performance parity

## ğŸ“š Related Files

- `full_coverage_test_config.json` - Test configuration
- `full_coverage_test_runner.py` - Test execution Glimpse
- `run_full_tests.bat` - Windows automation script
- `assistant_v2_core.py` - System under test
- `api/main.py` - API server entry point
- `deployment_manager.py` - Deployment configuration

## ğŸ¤ Contributing

To add new test cases:
1. Edit `full_coverage_test_config.json`
2. Add appropriate metadata for API selection
3. Implement test method in `EchoesAPITester` if needed
4. Update documentation

## ğŸ“„ License

This test suite is part of the Echoes Assistant V2 project.

---

**Ready to validate your OpenAI API migration? Run the tests now!** ğŸš€
