{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7d0c1bb",
   "metadata": {},
   "source": [
    "# Instruction Processing Pipeline Analysis\n",
    "\n",
    "This notebook analyzes the core instruction processing pipeline of the realtime system and provides feedback analysis for improvements.\n",
    "\n",
    "## System Overview\n",
    "1. Input Reception (`server_sse.py`)\n",
    "2. Orchestration (`realtime_preview.py`)\n",
    "3. Input Adaptation (`input_adapter.py`)\n",
    "4. Trajectory Analysis (`core_trajectory.py`)\n",
    "5. Visual Rendering (`visual_renderer.py`)\n",
    "6. Security & Broadcast (`security_integration.py`)\n",
    "\n",
    "## Feedback Analysis\n",
    "\n",
    "### 1. Architecture Review\n",
    "- **Potential Concerns:** \n",
    "  - SSE scalability with many clients\n",
    "  - Security of direct file operations\n",
    "  - Trajectory engine's memory usage\n",
    "\n",
    "### 2. Code Quality\n",
    "- **Areas for Improvement:**\n",
    "  - Add type hints in visual renderer\n",
    "  - Implement retry logic in SSE client\n",
    "  - Add input validation in InputAdapter\n",
    "\n",
    "### 3. Documentation\n",
    "- **Enhancements:**\n",
    "  - Add performance benchmarks\n",
    "  - Include error handling examples\n",
    "  - Document production deployment\n",
    "\n",
    "### 4. Testing\n",
    "- **Coverage Gaps:**\n",
    "  - Test race conditions\n",
    "  - Security test suite\n",
    "  - Load testing\n",
    "\n",
    "### 5. Security\n",
    "- **Considerations:**\n",
    "  - Rate limiting\n",
    "  - Input sanitization\n",
    "  - Authentication\n",
    "\n",
    "### 6. Performance\n",
    "- **Optimizations:**\n",
    "  - Profile CPU/memory\n",
    "  - Batch trajectory processing\n",
    "  - Compression for large payloads\n",
    "\n",
    "### 7. User Experience\n",
    "- **Improvements:**\n",
    "  - Progress indicators\n",
    "  - Better error messages\n",
    "  - Client reconnection logic\n",
    "\n",
    "### 8. Future-Proofing\n",
    "- **Suggestions:**\n",
    "  - Version API\n",
    "  - Plugin architecture\n",
    "  - Telemetry\n",
    "\n",
    "### 9. Deployment\n",
    "- **Requirements:**\n",
    "  - Containerization\n",
    "  - Monitoring\n",
    "  - Backup strategy\n",
    "\n",
    "### 10. Team Alignment\n",
    "- **Discussion Points:**\n",
    "  - Roadmap\n",
    "  - Integration\n",
    "  - Maintenance\n",
    "\n",
    "## Preparation Tasks\n",
    "\n",
    "1. **Performance Monitoring**\n",
    "   - Implement benchmarking with Locust\n",
    "   - Track CPU/memory metrics\n",
    "   - Set up continuous profiling\n",
    "\n",
    "2. **Security Implementation**\n",
    "   - Add input validation layers\n",
    "   - Implement rate limiting\n",
    "   - Set up authentication system\n",
    "\n",
    "3. **Documentation Updates**\n",
    "   - Create architecture diagrams\n",
    "   - Document performance characteristics\n",
    "   - Detail security measures\n",
    "\n",
    "4. **Testing Infrastructure**\n",
    "   - Set up integration test suite\n",
    "   - Implement load testing\n",
    "   - Create security test cases\n",
    "\n",
    "5. **Deployment Pipeline**\n",
    "   - Configure container orchestration\n",
    "   - Set up monitoring and alerts\n",
    "   - Implement backup procedures\n",
    "\n",
    "6. **Team Resources**\n",
    "   - Prepare technical presentations\n",
    "   - Create feedback collection system\n",
    "   - Document maintenance procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74e4605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup imports\n",
    "import os\n",
    "import pathlib\n",
    "import ast\n",
    "from typing import Dict, List, Set\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define paths to core components\n",
    "COMPONENTS = {\n",
    "    'server': pathlib.Path('d:/realtime/server_sse.py'),\n",
    "    'orchestrator': pathlib.Path('d:/realtime/realtime_preview.py'),\n",
    "    'input': pathlib.Path('d:/realtime/input_adapter.py'),\n",
    "    'trajectory': pathlib.Path('d:/realtime/core_trajectory.py'),\n",
    "    'renderer': pathlib.Path('d:/realtime/visual_renderer.py'),\n",
    "    'security': pathlib.Path('d:/realtime/security_integration.py')\n",
    "}\n",
    "\n",
    "@dataclass\n",
    "class ComponentInfo:\n",
    "    \"\"\"Store analyzed information about a component\"\"\"\n",
    "    name: str\n",
    "    classes: List[str]\n",
    "    methods: List[str]\n",
    "    calls: List[str]\n",
    "    dependencies: Set[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21feb481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SERVER Component:\n",
      "Classes: PreviewRequestHandler, SSEHub, ServerState\n",
      "Methods: 12\n",
      "Dependencies: Any, BaseHTTPRequestHandler, Dict, Empty, List, Path, Queue, ThreadingHTTPServer, __future__, annotations, create_glimpse, http, json, pathlib, queue, realtime_preview, threading, time, typing\n",
      "Sample calls: Path, Queue, SSEHub, ServerState, ThreadingHTTPServer\n",
      "\n",
      "ORCHESTRATOR Component:\n",
      "Classes: GlimpseConfiguration, GlimpseOrchestrator, GlimpseState\n",
      "Methods: 18\n",
      "Dependencies: Any, Callable, Dict, InputAdapter, InputEventType, List, Optional, Path, PreviewFrame, SecurityContext, SecurityManager, TrajectoryDirection, TrajectoryEngine, VisualRenderer, VisualizationMode, __future__, annotations, core_trajectory, dataclass, dataclasses, field, input_adapter, json, logging, pathlib, security_integration, time, typing, visual_renderer\n",
      "Sample calls: GlimpseConfiguration, GlimpseOrchestrator, GlimpseState, InputAdapter, LOG.error\n",
      "\n",
      "INPUT Component:\n",
      "Classes: AdaptationContext, InputAdapter, InputEvent, InputEventType\n",
      "Methods: 17\n",
      "Dependencies: Any, Callable, Dict, Enum, List, Optional, __future__, annotations, dataclass, dataclasses, difflib, enum, field, time, typing\n",
      "Sample calls: AdaptationContext, InputEvent, common_continuations.items, context.suggestions.extend, difflib.unified_diff\n",
      "\n",
      "TRAJECTORY Component:\n",
      "Classes: TrajectoryDirection, TrajectoryEngine, TrajectoryPoint, TrajectorySegment\n",
      "Methods: 15\n",
      "Dependencies: Any, Callable, Dict, Enum, List, Optional, __future__, annotations, collections, dataclass, dataclasses, deque, enum, field, json, time, typing\n",
      "Sample calls: TrajectoryPoint, TrajectorySegment, analyzer, chain.append, deque\n",
      "\n",
      "RENDERER Component:\n",
      "Classes: PreviewFrame, VisualElement, VisualRenderer, VisualizationMode\n",
      "Methods: 20\n",
      "Dependencies: Any, Dict, Enum, Image, ImageDraw, ImageFont, List, Optional, PIL, __future__, annotations, dataclass, dataclasses, enum, field, json, random, time, typing\n",
      "Sample calls: Image.new, ImageDraw.Draw, ImageFont.load_default, ImageFont.truetype, PreviewFrame\n",
      "\n",
      "SECURITY Component:\n",
      "Classes: SecurityContext, SecurityManager\n",
      "Methods: 15\n",
      "Dependencies: Any, Dict, List, Optional, Path, __future__, annotations, dataclass, dataclasses, importlib, json, logging, pathlib, sys, time, typing\n",
      "Sample calls: LOG.error, LOG.info, LOG.setLevel, LOG.warning, Orchestrator\n"
     ]
    }
   ],
   "source": [
    "def extract_name_from_node(node: ast.AST) -> str:\n",
    "    \"\"\"Extract a name from an AST node, handling various node types\"\"\"\n",
    "    if isinstance(node, ast.Name):\n",
    "        return node.id\n",
    "    elif isinstance(node, ast.Attribute):\n",
    "        # Handle nested attributes (e.g., a.b.c)\n",
    "        parts = []\n",
    "        current = node\n",
    "        while isinstance(current, ast.Attribute):\n",
    "            parts.append(current.attr)\n",
    "            current = current.value\n",
    "        if isinstance(current, ast.Name):\n",
    "            parts.append(current.id)\n",
    "        return '.'.join(reversed(parts))\n",
    "    return ''\n",
    "\n",
    "def analyze_component(path: pathlib.Path) -> ComponentInfo:\n",
    "    \"\"\"Analyze a component's source code to extract key information\"\"\"\n",
    "    try:\n",
    "        code = path.read_text(encoding='utf-8')\n",
    "        tree = ast.parse(code)\n",
    "        \n",
    "        classes = []\n",
    "        methods = []\n",
    "        calls = []\n",
    "        dependencies = set()\n",
    "        \n",
    "        for node in ast.walk(tree):\n",
    "            # Collect class definitions\n",
    "            if isinstance(node, ast.ClassDef):\n",
    "                classes.append(node.name)\n",
    "                \n",
    "            # Collect method definitions\n",
    "            elif isinstance(node, ast.FunctionDef):\n",
    "                methods.append(node.name)\n",
    "                \n",
    "            # Collect function calls\n",
    "            elif isinstance(node, ast.Call):\n",
    "                call_name = extract_name_from_node(node.func)\n",
    "                if call_name:\n",
    "                    calls.append(call_name)\n",
    "                    \n",
    "            # Collect imports\n",
    "            elif isinstance(node, ast.Import):\n",
    "                for alias in node.names:\n",
    "                    dependencies.add(alias.name.split('.')[0])\n",
    "            elif isinstance(node, ast.ImportFrom):\n",
    "                if node.module:\n",
    "                    dependencies.add(node.module.split('.')[0])\n",
    "                for alias in node.names:\n",
    "                    dependencies.add(alias.name.split('.')[0])\n",
    "        \n",
    "        return ComponentInfo(\n",
    "            name=path.stem,\n",
    "            classes=sorted(set(classes)),\n",
    "            methods=sorted(set(methods)),\n",
    "            calls=sorted(set(calls)),\n",
    "            dependencies=dependencies\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing {path}: {e}\")\n",
    "        return ComponentInfo(name=path.stem, classes=[], methods=[], calls=[], dependencies=set())\n",
    "\n",
    "# Analyze all components\n",
    "component_analysis = {\n",
    "    name: analyze_component(path)\n",
    "    for name, path in COMPONENTS.items()\n",
    "}\n",
    "\n",
    "# Print component summaries\n",
    "for name, info in component_analysis.items():\n",
    "    print(f\"\\n{name.upper()} Component:\")\n",
    "    print(f\"Classes: {', '.join(info.classes)}\")\n",
    "    print(f\"Methods: {len(info.methods)}\")\n",
    "    print(f\"Dependencies: {', '.join(sorted(info.dependencies))}\")\n",
    "    print(f\"Sample calls: {', '.join(info.calls[:5]) if info.calls else 'None'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1090fea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Instruction Processing Methods:\n",
      "\n",
      "SERVER:\n",
      "  - _handle_input (handle)\n",
      "    Called by: self._handle_input\n",
      "\n",
      "ORCHESTRATOR:\n",
      "  - process_input (process)\n",
      "\n",
      "Component Interaction Flow:\n",
      "\n",
      "SERVER:\n",
      "  Imports from: orchestrator\n",
      "  Calls to: input, orchestrator, renderer, security, trajectory\n",
      "\n",
      "ORCHESTRATOR:\n",
      "  Imports from: input, renderer, security, trajectory\n",
      "  Calls to: input, renderer, security, server, trajectory\n",
      "\n",
      "INPUT:\n",
      "  Calls to: orchestrator, renderer, security, trajectory\n",
      "\n",
      "TRAJECTORY:\n",
      "  Calls to: input, orchestrator, renderer, security\n",
      "\n",
      "RENDERER:\n",
      "  Calls to: input, orchestrator, security, trajectory\n",
      "\n",
      "SECURITY:\n",
      "  Calls to: input, orchestrator, renderer, trajectory\n",
      "\n",
      "Component Complexity Metrics:\n",
      "\n",
      "SERVER:\n",
      "  classes: 3\n",
      "  methods: 12\n",
      "  calls: 45\n",
      "  dependencies: 19\n",
      "  instruction_handlers: 1\n",
      "\n",
      "ORCHESTRATOR:\n",
      "  classes: 3\n",
      "  methods: 18\n",
      "  calls: 67\n",
      "  dependencies: 29\n",
      "  instruction_handlers: 1\n",
      "\n",
      "INPUT:\n",
      "  classes: 4\n",
      "  methods: 17\n",
      "  calls: 31\n",
      "  dependencies: 15\n",
      "  instruction_handlers: 0\n",
      "\n",
      "TRAJECTORY:\n",
      "  classes: 4\n",
      "  methods: 15\n",
      "  calls: 32\n",
      "  dependencies: 17\n",
      "  instruction_handlers: 0\n",
      "\n",
      "RENDERER:\n",
      "  classes: 4\n",
      "  methods: 20\n",
      "  calls: 56\n",
      "  dependencies: 19\n",
      "  instruction_handlers: 0\n",
      "\n",
      "SECURITY:\n",
      "  classes: 2\n",
      "  methods: 15\n",
      "  calls: 45\n",
      "  dependencies: 16\n",
      "  instruction_handlers: 0\n"
     ]
    }
   ],
   "source": [
    "def find_instruction_handlers(info: ComponentInfo) -> List[Dict[str, str]]:\n",
    "    \"\"\"Find methods that handle instruction processing\"\"\"\n",
    "    instruction_patterns = {\n",
    "        'process': r'process.*instruction|process.*input|process.*command',\n",
    "        'handle': r'handle.*instruction|handle.*input|handle.*command',\n",
    "        'execute': r'execute.*instruction|execute.*command',\n",
    "        'validate': r'validate.*instruction|validate.*input',\n",
    "        'transform': r'transform.*instruction|transform.*input'\n",
    "    }\n",
    "    \n",
    "    handlers = []\n",
    "    for method in info.methods:\n",
    "        for category, pattern in instruction_patterns.items():\n",
    "            if re.search(pattern, method.lower()):\n",
    "                handlers.append({\n",
    "                    'method': method,\n",
    "                    'category': category,\n",
    "                    'calls': [call for call in info.calls if method in call]\n",
    "                })\n",
    "    return handlers\n",
    "\n",
    "# Find instruction handling methods in each component\n",
    "print(\"\\nInstruction Processing Methods:\")\n",
    "for name, info in component_analysis.items():\n",
    "    handlers = find_instruction_handlers(info)\n",
    "    if handlers:\n",
    "        print(f\"\\n{name.upper()}:\")\n",
    "        for handler in handlers:\n",
    "            print(f\"  - {handler['method']} ({handler['category']})\")\n",
    "            if handler['calls']:\n",
    "                print(f\"    Called by: {', '.join(handler['calls'])}\")\n",
    "\n",
    "# Map the flow between components\n",
    "def map_component_flow() -> Dict[str, Dict[str, Set[str]]]:\n",
    "    \"\"\"Map how components interact with each other\"\"\"\n",
    "    flow = defaultdict(lambda: {'imports': set(), 'calls': set()})\n",
    "    \n",
    "    for name, info in component_analysis.items():\n",
    "        # Check imports\n",
    "        for dep in info.dependencies:\n",
    "            for other_name, other_info in component_analysis.items():\n",
    "                if dep == other_info.name:\n",
    "                    flow[name]['imports'].add(other_name)\n",
    "        \n",
    "        # Check method calls\n",
    "        for call in info.calls:\n",
    "            for other_name, other_info in component_analysis.items():\n",
    "                if name != other_name:\n",
    "                    if any(method in call for method in other_info.methods):\n",
    "                        flow[name]['calls'].add(other_name)\n",
    "    \n",
    "    return flow\n",
    "\n",
    "print(\"\\nComponent Interaction Flow:\")\n",
    "flow = map_component_flow()\n",
    "for source, interactions in flow.items():\n",
    "    if interactions['imports'] or interactions['calls']:\n",
    "        print(f\"\\n{source.upper()}:\")\n",
    "        if interactions['imports']:\n",
    "            print(f\"  Imports from: {', '.join(sorted(interactions['imports']))}\")\n",
    "        if interactions['calls']:\n",
    "            print(f\"  Calls to: {', '.join(sorted(interactions['calls']))}\")\n",
    "\n",
    "# Calculate component complexity\n",
    "def calculate_complexity(info: ComponentInfo) -> Dict[str, int]:\n",
    "    \"\"\"Calculate complexity metrics for a component\"\"\"\n",
    "    return {\n",
    "        'classes': len(info.classes),\n",
    "        'methods': len(info.methods),\n",
    "        'calls': len(info.calls),\n",
    "        'dependencies': len(info.dependencies),\n",
    "        'instruction_handlers': len(find_instruction_handlers(info))\n",
    "    }\n",
    "\n",
    "print(\"\\nComponent Complexity Metrics:\")\n",
    "for name, info in component_analysis.items():\n",
    "    metrics = calculate_complexity(info)\n",
    "    print(f\"\\n{name.upper()}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b62ac48",
   "metadata": {},
   "source": [
    "## Pipeline Implementation Analysis\n",
    "\n",
    "The instruction processing pipeline follows these stages:\n",
    "\n",
    "1. **Input Reception** (`server_sse.py`)\n",
    "   - Handles incoming POST requests to `/input`\n",
    "   - Validates request format and authentication\n",
    "   - Forwards to orchestrator\n",
    "\n",
    "2. **Orchestration** (`realtime_preview.py`)\n",
    "   - Coordinates processing flow\n",
    "   - Manages component interactions\n",
    "   - Handles error cases and retries\n",
    "\n",
    "3. **Input Processing** (`input_adapter.py`)\n",
    "   - Normalizes input format\n",
    "   - Tracks edit history\n",
    "   - Handles undo/redo operations\n",
    "\n",
    "4. **Trajectory Analysis** (`core_trajectory.py`)\n",
    "   - Analyzes instruction patterns\n",
    "   - Builds cause-effect chains\n",
    "   - Calculates confidence scores\n",
    "\n",
    "5. **Visual Rendering** (`visual_renderer.py`)\n",
    "   - Generates preview frames\n",
    "   - Handles different output formats\n",
    "   - Manages render queue\n",
    "\n",
    "6. **Security & Broadcast** (`security_integration.py`)\n",
    "   - Validates operations\n",
    "   - Manages permissions\n",
    "   - Broadcasts updates via SSE\n",
    "\n",
    "## Extension Points\n",
    "\n",
    "1. Custom Input Adapters\n",
    "   - Implement `InputAdapter` interface\n",
    "   - Register in orchestrator\n",
    "\n",
    "2. Trajectory Analyzers\n",
    "   - Extend `TrajectoryEngine`\n",
    "   - Add custom metrics\n",
    "\n",
    "3. Render Providers\n",
    "   - Implement `VisualRenderer` interface\n",
    "   - Support new output formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd58940",
   "metadata": {},
   "source": [
    "## Enhanced Pipeline Analysis\n",
    "\n",
    "From the improved component analysis, we can now see:\n",
    "\n",
    "1. **Core Components Hierarchy**\n",
    "   - Entry point: `server_sse.py` handles HTTP/SSE endpoints\n",
    "   - Coordinator: `realtime_preview.py` orchestrates processing\n",
    "   - Processors: `input_adapter.py` and `core_trajectory.py` handle transformations\n",
    "   - Output: `visual_renderer.py` generates results\n",
    "   - Security: `security_integration.py` validates operations\n",
    "\n",
    "2. **Key Integration Points**\n",
    "   - SSE event broadcasting system\n",
    "   - Input processing pipeline\n",
    "   - Security validation gates\n",
    "   - Visual rendering queue\n",
    "\n",
    "3. **Extension Mechanisms**\n",
    "   - Custom input adapters\n",
    "   - Trajectory analyzers\n",
    "   - Render providers\n",
    "   - Security validators\n",
    "\n",
    "4. **Component Dependencies**\n",
    "   - Direct method calls\n",
    "   - Import relationships\n",
    "   - Event-based communication\n",
    "   - Shared state management\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **SSE Implementation**\n",
    "   - Document event types and payloads\n",
    "   - Map broadcast patterns\n",
    "   - Analyze client reconnection handling\n",
    "\n",
    "2. **Security Integration**\n",
    "   - Review validation gates\n",
    "   - Document permission model\n",
    "   - Map authentication flow\n",
    "\n",
    "3. **Performance Analysis**\n",
    "   - Identify bottlenecks\n",
    "   - Monitor processing times\n",
    "   - Optimize critical paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61242ee0",
   "metadata": {},
   "source": [
    "## Implementation Examples\n",
    "\n",
    "The following sections demonstrate practical implementations of pipeline extensions, showing how to integrate with each component of the system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8264291d",
   "metadata": {},
   "source": [
    "### 1. Custom Input Adapter\n",
    "\n",
    "The `MarkdownInputAdapter` extends the base input adapter to provide markdown-specific suggestions and formatting. This example shows how to:\n",
    "- Extend the base `InputAdapter` class\n",
    "- Register custom suggestion providers\n",
    "- Handle markdown-specific patterns\n",
    "- Integrate with the orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52f44162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from input_adapter import InputAdapter, AdaptationContext\n",
    "from typing import List\n",
    "import re\n",
    "\n",
    "class MarkdownInputAdapter(InputAdapter):\n",
    "    \"\"\"Input adapter with markdown-aware suggestions\"\"\"\n",
    "    \n",
    "    def __init__(self, buffer_size: int = 50):\n",
    "        super().__init__(buffer_size)\n",
    "        # Register markdown suggestion provider\n",
    "        self.register_suggestion_provider(self._markdown_suggestions)\n",
    "    \n",
    "    def _markdown_suggestions(self, context: AdaptationContext) -> List[str]:\n",
    "        \"\"\"Generate markdown-specific suggestions\"\"\"\n",
    "        content = context.current_content\n",
    "        cursor = context.cursor_position\n",
    "        \n",
    "        suggestions = []\n",
    "        \n",
    "        # Get current line\n",
    "        lines = content[:cursor].split('\\n')\n",
    "        current_line = lines[-1] if lines else \"\"\n",
    "        \n",
    "        # Heading completion\n",
    "        if current_line.startswith('#'):\n",
    "            level = len(re.match(r'^#+', current_line).group())\n",
    "            suggestions.append(f\"{'#' * level} Heading level {level}\")\n",
    "        \n",
    "        # List continuation\n",
    "        if re.match(r'^\\s*[-*+]\\s', current_line):\n",
    "            suggestions.append(\"Continue list\")\n",
    "            suggestions.append(\"Nest list item\")\n",
    "        \n",
    "        # Link template\n",
    "        if '[' in current_line and ']' not in current_line:\n",
    "            suggestions.append(\"[text](url)\")\n",
    "        \n",
    "        # Code block\n",
    "        if current_line.strip() == '```':\n",
    "            suggestions.append(\"```python\\n# code here\\n```\")\n",
    "            suggestions.append(\"```javascript\\n// code here\\n```\")\n",
    "        \n",
    "        return suggestions[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be65f025",
   "metadata": {},
   "source": [
    "### 2. Custom Trajectory Analyzer\n",
    "\n",
    "The `CodeComplexityAnalyzer` extends the trajectory analysis system to track code complexity trends. This example demonstrates:\n",
    "- Complexity metric calculation\n",
    "- Pattern-based code analysis\n",
    "- Integration with the trajectory engine\n",
    "- Trend analysis for code evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d2db942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core_trajectory import TrajectoryEngine, TrajectoryDirection, TrajectoryPoint\n",
    "from typing import List\n",
    "import re\n",
    "\n",
    "class CodeComplexityAnalyzer:\n",
    "    \"\"\"Analyzes code complexity trends in trajectory\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.complexity_keywords = [\n",
    "            'if', 'else', 'elif', 'for', 'while', 'try', 'except',\n",
    "            'def', 'class', 'async', 'await', 'lambda'\n",
    "        ]\n",
    "    \n",
    "    def analyze_direction(self, points: List[TrajectoryPoint]) -> TrajectoryDirection:\n",
    "        \"\"\"Determine trajectory based on code complexity\"\"\"\n",
    "        if len(points) < 3:\n",
    "            return TrajectoryDirection.UNCERTAIN\n",
    "        \n",
    "        recent = points[-5:]\n",
    "        complexities = [self._compute_complexity(p.content) for p in recent]\n",
    "        \n",
    "        # Trend analysis\n",
    "        if len(complexities) < 2:\n",
    "            return TrajectoryDirection.UNCERTAIN\n",
    "        \n",
    "        trend = complexities[-1] - complexities[0]\n",
    "        variance = max(complexities) - min(complexities)\n",
    "        \n",
    "        if trend > variance * 0.5:\n",
    "            return TrajectoryDirection.EXPANDING  # Adding complexity\n",
    "        elif trend < -variance * 0.5:\n",
    "            return TrajectoryDirection.CONVERGING  # Simplifying\n",
    "        elif variance > sum(complexities) / len(complexities) * 0.4:\n",
    "            return TrajectoryDirection.PIVOTING  # Refactoring\n",
    "        else:\n",
    "            return TrajectoryDirection.STABLE\n",
    "    \n",
    "    def _compute_complexity(self, content: str) -> float:\n",
    "        \"\"\"Simple complexity metric based on control structures\"\"\"\n",
    "        score = 0.0\n",
    "        \n",
    "        for keyword in self.complexity_keywords:\n",
    "            # Count keyword occurrences\n",
    "            score += len(re.findall(rf'\\b{keyword}\\b', content))\n",
    "        \n",
    "        # Nesting depth (approximate)\n",
    "        max_indent = 0\n",
    "        for line in content.split('\\n'):\n",
    "            if line.strip():\n",
    "                indent = len(line) - len(line.lstrip())\n",
    "                max_indent = max(max_indent, indent // 4)\n",
    "        \n",
    "        score += max_indent * 2\n",
    "        \n",
    "        # Normalize by content length\n",
    "        return score / max(len(content), 1) * 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e50f156",
   "metadata": {},
   "source": [
    "### 3. Integration Testing\n",
    "\n",
    "The following example shows how to test custom extensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1821efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running extension tests in isolation...\n",
      "\n",
      "Simulating extension testing:\n",
      "- Testing CodeComplexityAnalyzer...\n",
      "- Testing MarkdownInputAdapter...\n",
      "\n",
      "Test Results:\n",
      "\n",
      "complexity_analyzer:\n",
      "  Success: True\n",
      "  Details: Analyzer processed nested code structure\n",
      "  Complexity Score: 195.6521739130435\n",
      "\n",
      "markdown_adapter:\n",
      "  Success: True\n",
      "  Details: Markdown adapter provided heading suggestions\n",
      "  Suggestions: 1\n"
     ]
    }
   ],
   "source": [
    "# Example testing code for extensions\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any\n",
    "import re\n",
    "\n",
    "# Mock classes for testing\n",
    "@dataclass\n",
    "class AdaptationContext:\n",
    "    \"\"\"Mock context for testing input adapters\"\"\"\n",
    "    current_content: str\n",
    "    cursor_position: int\n",
    "\n",
    "class InputAdapter:\n",
    "    \"\"\"Mock base input adapter\"\"\"\n",
    "    def __init__(self, buffer_size: int = 50):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.suggestion_providers = []\n",
    "    \n",
    "    def register_suggestion_provider(self, provider):\n",
    "        self.suggestion_providers.append(provider)\n",
    "\n",
    "class MockTrajectoryPoint:\n",
    "    \"\"\"Mock trajectory point for testing\"\"\"\n",
    "    def __init__(self, content: str):\n",
    "        self.content = content\n",
    "\n",
    "# Import test classes\n",
    "from core_trajectory import TrajectoryDirection\n",
    "\n",
    "class CodeComplexityAnalyzer:\n",
    "    \"\"\"Analyzes code complexity trends in trajectory\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.complexity_keywords = [\n",
    "            'if', 'else', 'elif', 'for', 'while', 'try', 'except',\n",
    "            'def', 'class', 'async', 'await', 'lambda'\n",
    "        ]\n",
    "    \n",
    "    def _compute_complexity(self, content: str) -> float:\n",
    "        \"\"\"Simple complexity metric based on control structures\"\"\"\n",
    "        score = 0.0\n",
    "        \n",
    "        for keyword in self.complexity_keywords:\n",
    "            # Count keyword occurrences\n",
    "            score += len(re.findall(rf'\\b{keyword}\\b', content))\n",
    "        \n",
    "        # Nesting depth (approximate)\n",
    "        max_indent = 0\n",
    "        for line in content.split('\\n'):\n",
    "            if line.strip():\n",
    "                indent = len(line) - len(line.lstrip())\n",
    "                max_indent = max(max_indent, indent // 4)\n",
    "        \n",
    "        score += max_indent * 2\n",
    "        \n",
    "        # Normalize by content length\n",
    "        return score / max(len(content), 1) * 1000\n",
    "\n",
    "class MarkdownInputAdapter(InputAdapter):\n",
    "    \"\"\"Input adapter with markdown-aware suggestions\"\"\"\n",
    "    \n",
    "    def __init__(self, buffer_size: int = 50):\n",
    "        super().__init__(buffer_size)\n",
    "        # Register markdown suggestion provider\n",
    "        self.register_suggestion_provider(self._markdown_suggestions)\n",
    "    \n",
    "    def _markdown_suggestions(self, context: AdaptationContext) -> List[str]:\n",
    "        \"\"\"Generate markdown-specific suggestions\"\"\"\n",
    "        content = context.current_content\n",
    "        cursor = context.cursor_position\n",
    "        \n",
    "        suggestions = []\n",
    "        \n",
    "        # Get current line\n",
    "        lines = content[:cursor].split('\\n')\n",
    "        current_line = lines[-1] if lines else \"\"\n",
    "        \n",
    "        # Heading completion\n",
    "        if current_line.startswith('#'):\n",
    "            level = len(re.match(r'^#+', current_line).group())\n",
    "            suggestions.append(f\"{'#' * level} Heading level {level}\")\n",
    "        \n",
    "        # List continuation\n",
    "        if re.match(r'^\\s*[-*+]\\s', current_line):\n",
    "            suggestions.append(\"Continue list\")\n",
    "            suggestions.append(\"Nest list item\")\n",
    "        \n",
    "        # Link template\n",
    "        if '[' in current_line and ']' not in current_line:\n",
    "            suggestions.append(\"[text](url)\")\n",
    "        \n",
    "        # Code block\n",
    "        if current_line.strip() == '```':\n",
    "            suggestions.append(\"```python\\n# code here\\n```\")\n",
    "            suggestions.append(\"```javascript\\n// code here\\n```\")\n",
    "        \n",
    "        return suggestions[:3]\n",
    "\n",
    "def test_custom_extensions():\n",
    "    \"\"\"Test custom pipeline extensions\"\"\"\n",
    "    print(\"\\nSimulating extension testing:\")\n",
    "    results = []\n",
    "    \n",
    "    print(\"- Testing CodeComplexityAnalyzer...\")\n",
    "    # Test complexity analyzer\n",
    "    analyzer = CodeComplexityAnalyzer()\n",
    "    test_code = \"if x:\\n    if y:\\n        if z:\\n            pass\"\n",
    "    complexity = analyzer._compute_complexity(test_code)\n",
    "    \n",
    "    results.append({\n",
    "        'test': 'complexity_analyzer',\n",
    "        'success': True,\n",
    "        'complexity': complexity,\n",
    "        'details': 'Analyzer processed nested code structure'\n",
    "    })\n",
    "    \n",
    "    print(\"- Testing MarkdownInputAdapter...\")\n",
    "    # Test markdown adapter\n",
    "    adapter = MarkdownInputAdapter()\n",
    "    context = AdaptationContext(\n",
    "        current_content=\"# \",\n",
    "        cursor_position=2\n",
    "    )\n",
    "    suggestions = adapter._markdown_suggestions(context)\n",
    "    \n",
    "    results.append({\n",
    "        'test': 'markdown_adapter',\n",
    "        'success': bool(suggestions),\n",
    "        'suggestions': len(suggestions),\n",
    "        'details': 'Markdown adapter provided heading suggestions'\n",
    "    })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run tests without server connection\n",
    "print(\"Running extension tests in isolation...\")\n",
    "test_results = test_custom_extensions()\n",
    "\n",
    "# Display results\n",
    "print(\"\\nTest Results:\")\n",
    "for result in test_results:\n",
    "    print(f\"\\n{result['test']}:\")\n",
    "    print(f\"  Success: {result['success']}\")\n",
    "    print(f\"  Details: {result['details']}\")\n",
    "    if 'complexity' in result:\n",
    "        print(f\"  Complexity Score: {result['complexity']}\")\n",
    "    if 'suggestions' in result:\n",
    "        print(f\"  Suggestions: {result['suggestions']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100059c6",
   "metadata": {},
   "source": [
    "## System Integration Checklist\n",
    "\n",
    "When implementing these extensions:\n",
    "\n",
    "1. **Component Testing**\n",
    "   - Test each extension in isolation\n",
    "   - Verify edge cases and error handling\n",
    "   - Check performance impact\n",
    "\n",
    "2. **Security Considerations**\n",
    "   - Review custom validation rules\n",
    "   - Test security boundaries\n",
    "   - Validate input sanitization\n",
    "\n",
    "3. **Performance Monitoring**\n",
    "   - Profile extension overhead\n",
    "   - Monitor memory usage\n",
    "   - Track processing times\n",
    "\n",
    "4. **Documentation**\n",
    "   - Document extension APIs\n",
    "   - Provide usage examples\n",
    "   - Include configuration options\n",
    "\n",
    "5. **Deployment**\n",
    "   - Set up logging\n",
    "   - Configure monitoring\n",
    "   - Create rollback procedures\n",
    "   - Test under load\n",
    "\n",
    "6. **Client Integration**\n",
    "   - Update client SDKs\n",
    "   - Document new features\n",
    "   - Provide migration guides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ead8c78",
   "metadata": {},
   "source": [
    "## Client Integration Examples\n",
    "\n",
    "The following Python client implementation shows how to:\n",
    "- Connect to the SSE stream\n",
    "- Send instructions\n",
    "- Handle preview updates\n",
    "- Manage the connection lifecycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ebc2b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GlimpseClient Features Exploration\n",
      "=================================\n",
      "\n",
      "Connection Settings:\n",
      "Server URL: http://127.0.0.1:8765\n",
      "\n",
      "Available Methods:\n",
      "\n",
      "- connect:\n",
      "  Connect to SSE stream\n",
      "\n",
      "- disconnect:\n",
      "  Disconnect from server\n",
      "\n",
      "- handlers:\n",
      "  dict() -> new empty dictionary\n",
      "\n",
      "- on_preview:\n",
      "  Register preview handler\n",
      "\n",
      "- send_input:\n",
      "  Send input to server\n",
      "\n",
      "- server_url:\n",
      "  str(object='') -> str\n",
      "\n",
      "- session:\n",
      "  A Requests session.\n",
      "\n",
      "PreviewEvent Structure:\n",
      "Fields: stage, content, job_id, timestamp, metadata\n",
      "\n",
      "Example Input Payload:\n",
      "{\n",
      "  \"content\": \"print('Hello, World!')\",\n",
      "  \"action\": \"replace\",\n",
      "  \"start\": 0,\n",
      "  \"end\": 0,\n",
      "  \"timestamp\": \"2025-10-18T13:04:24.403819\"\n",
      "}\n",
      "\n",
      "Usage Examples:\n",
      "1. Connect to server:\n",
      "   client.connect()\n",
      "\n",
      "2. Register preview handler:\n",
      "   client.on_preview(lambda event: print(f'Preview: {event}'))\n",
      "\n",
      "3. Send input:\n",
      "   client.send_input('print(\"Hello\")')\n",
      "\n",
      "4. Disconnect:\n",
      "   client.disconnect()\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import sseclient\n",
    "import threading\n",
    "import json\n",
    "from typing import Callable, Dict, Any\n",
    "from dataclasses import dataclass, fields\n",
    "from datetime import datetime\n",
    "\n",
    "@dataclass\n",
    "class PreviewEvent:\n",
    "    \"\"\"Structure for preview events\"\"\"\n",
    "    stage: str\n",
    "    content: str\n",
    "    job_id: str\n",
    "    timestamp: datetime\n",
    "    metadata: Dict[str, Any]\n",
    "\n",
    "class GlimpseClient:\n",
    "    \"\"\"Python client for Glimpse SSE server\"\"\"\n",
    "    \n",
    "    def __init__(self, server_url: str = \"http://127.0.0.1:8765\"):\n",
    "        self.server_url = server_url\n",
    "        self.handlers: Dict[str, Callable] = {}\n",
    "        self._stream_thread = None\n",
    "        self._running = False\n",
    "        self.session = requests.Session()\n",
    "    \n",
    "    def connect(self):\n",
    "        \"\"\"Connect to SSE stream\"\"\"\n",
    "        self._running = True\n",
    "        self._stream_thread = threading.Thread(target=self._listen_stream, daemon=True)\n",
    "        self._stream_thread.start()\n",
    "    \n",
    "    def _listen_stream(self):\n",
    "        \"\"\"Listen to SSE stream in background thread\"\"\"\n",
    "        try:\n",
    "            response = self.session.get(f\"{self.server_url}/events\", stream=True)\n",
    "            client = sseclient.SSEClient(response)\n",
    "            \n",
    "            for event in client.events():\n",
    "                if not self._running:\n",
    "                    break\n",
    "                \n",
    "                if event.event == \"preview\":\n",
    "                    data = json.loads(event.data)\n",
    "                    preview = PreviewEvent(\n",
    "                        stage=data.get('stage', 'unknown'),\n",
    "                        content=data.get('content', ''),\n",
    "                        job_id=data.get('job_id', ''),\n",
    "                        timestamp=datetime.now(),\n",
    "                        metadata=data.get('metadata', {})\n",
    "                    )\n",
    "                    self._handle_preview(preview)\n",
    "        except Exception as e:\n",
    "            print(f\"Stream error: {e}\")\n",
    "            if self._running:\n",
    "                # Try to reconnect after a delay\n",
    "                threading.Timer(5.0, self._listen_stream).start()\n",
    "    \n",
    "    def send_input(self, content: str, action: str = \"replace\", \n",
    "                   start: int = 0, end: int = 0) -> Dict[str, Any]:\n",
    "        \"\"\"Send input to server\"\"\"\n",
    "        payload = {\n",
    "            \"content\": content,\n",
    "            \"action\": action,\n",
    "            \"start\": start,\n",
    "            \"end\": end,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        response = self.session.post(\n",
    "            f\"{self.server_url}/input\",\n",
    "            json=payload\n",
    "        )\n",
    "        return response.json()\n",
    "    \n",
    "    def on_preview(self, handler: Callable[[PreviewEvent], None]):\n",
    "        \"\"\"Register preview handler\"\"\"\n",
    "        self.handlers[\"preview\"] = handler\n",
    "    \n",
    "    def _handle_preview(self, preview: PreviewEvent):\n",
    "        \"\"\"Handle preview event\"\"\"\n",
    "        if \"preview\" in self.handlers:\n",
    "            self.handlers[\"preview\"](preview)\n",
    "    \n",
    "    def disconnect(self):\n",
    "        \"\"\"Disconnect from server\"\"\"\n",
    "        self._running = False\n",
    "        if self.session:\n",
    "            self.session.close()\n",
    "\n",
    "# Demonstrate client API features without connecting to server\n",
    "def explore_client_api():\n",
    "    \"\"\"Explore the GlimpseClient API capabilities\"\"\"\n",
    "    client = GlimpseClient()\n",
    "    print(\"GlimpseClient Features Exploration\")\n",
    "    print(\"=================================\")\n",
    "    print(f\"\\nConnection Settings:\")\n",
    "    print(f\"Server URL: {client.server_url}\")\n",
    "    \n",
    "    # List and describe available methods\n",
    "    print(\"\\nAvailable Methods:\")\n",
    "    methods = [m for m in dir(client) if not m.startswith('_')]\n",
    "    for method in methods:\n",
    "        doc = getattr(client, method).__doc__ or \"No description\"\n",
    "        print(f\"\\n- {method}:\")\n",
    "        print(f\"  {doc.split('\\n')[0]}\")\n",
    "    \n",
    "    # Show PreviewEvent structure\n",
    "    print(\"\\nPreviewEvent Structure:\")\n",
    "    preview_fields = [field.name for field in fields(PreviewEvent)]\n",
    "    print(f\"Fields: {', '.join(preview_fields)}\")\n",
    "    \n",
    "    # Example payload structure\n",
    "    print(\"\\nExample Input Payload:\")\n",
    "    example_payload = {\n",
    "        \"content\": \"print('Hello, World!')\",\n",
    "        \"action\": \"replace\",\n",
    "        \"start\": 0,\n",
    "        \"end\": 0,\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "    print(json.dumps(example_payload, indent=2))\n",
    "    \n",
    "    print(\"\\nUsage Examples:\")\n",
    "    print(\"1. Connect to server:\")\n",
    "    print(\"   client.connect()\")\n",
    "    print(\"\\n2. Register preview handler:\")\n",
    "    print(\"   client.on_preview(lambda event: print(f'Preview: {event}'))\")\n",
    "    print(\"\\n3. Send input:\")\n",
    "    print(\"   client.send_input('print(\\\"Hello\\\")')\")\n",
    "    print(\"\\n4. Disconnect:\")\n",
    "    print(\"   client.disconnect()\")\n",
    "\n",
    "# Run API exploration\n",
    "explore_client_api()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6378a8",
   "metadata": {},
   "source": [
    "## Performance Monitoring\n",
    "\n",
    "The following examples demonstrate how to:\n",
    "1. Monitor processing times\n",
    "2. Track memory usage\n",
    "3. Profile critical operations\n",
    "4. Generate performance reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67805cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPerformance Monitoring Demo\u001b[0m\n",
      "=========================\n",
      "\n",
      "\u001b[1m1. Content Size Performance\u001b[0m\n",
      "-------------------------\n",
      "Processed   10 chars -> {'status': 'processed', 'length': 10}Processed   10 chars -> {'status': 'processed', 'length': 10}\n",
      "\n",
      "Processed  100 chars -> {'status': 'processed', 'length': 100}\n",
      "Processed  100 chars -> {'status': 'processed', 'length': 100}\n",
      "Processed 1000 chars -> {'status': 'processed', 'length': 1000}\n",
      "\n",
      "\u001b[1m2. Performance Metrics\u001b[0m\n",
      "-------------------------\n",
      "Total Operations    : 3\n",
      "Average Duration    : 0.1002s\n",
      "Operations/Second   : 11.82\n",
      "Memory Impact       : 0.00 MB\n",
      "Total Runtime       : 0.254s\n",
      "\n",
      "\u001b[1m3. Profile Analysis\u001b[0m\n",
      "-------------------------\n",
      "Sample profiling (100 chars):\n",
      "Processed 1000 chars -> {'status': 'processed', 'length': 1000}\n",
      "\n",
      "\u001b[1m2. Performance Metrics\u001b[0m\n",
      "-------------------------\n",
      "Total Operations    : 3\n",
      "Average Duration    : 0.1002s\n",
      "Operations/Second   : 11.82\n",
      "Memory Impact       : 0.00 MB\n",
      "Total Runtime       : 0.254s\n",
      "\n",
      "\u001b[1m3. Profile Analysis\u001b[0m\n",
      "-------------------------\n",
      "Sample profiling (100 chars):\n",
      "\n",
      "Top Operations (excluding framework):\n",
      "         614 function calls (609 primitive calls) in 0.117 seconds\n",
      "   Ordered by: cumulative time\n",
      "-------------------------------------------------------------------------------------\n",
      "  ncalls  tottime  percall  cumtime  percall  filename:lineno(function)\n",
      "-------------------------------------------------------------------------------------\n",
      "   List reduced from 149 to 5 due to restriction <5>\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      4/3    0.000    0.000    0.117    0.039 C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py:1970(_run_once)\n",
      "        2    0.000    0.000    0.072    0.036 C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\selectors.py:310(select)\n",
      "        2    0.000    0.000    0.072    0.036 C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\selectors.py:304(_select)\n",
      "\n",
      "Top Operations (excluding framework):\n",
      "         614 function calls (609 primitive calls) in 0.117 seconds\n",
      "   Ordered by: cumulative time\n",
      "-------------------------------------------------------------------------------------\n",
      "  ncalls  tottime  percall  cumtime  percall  filename:lineno(function)\n",
      "-------------------------------------------------------------------------------------\n",
      "   List reduced from 149 to 5 due to restriction <5>\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      4/3    0.000    0.000    0.117    0.039 C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\base_events.py:1970(_run_once)\n",
      "        2    0.000    0.000    0.072    0.036 C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\selectors.py:310(select)\n",
      "        2    0.000    0.000    0.072    0.036 C:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\selectors.py:304(_select)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import psutil\n",
    "import cProfile\n",
    "import pstats\n",
    "import io\n",
    "from functools import wraps\n",
    "from typing import Dict, List, Any, Pattern\n",
    "from dataclasses import dataclass\n",
    "import re\n",
    "from collections import deque\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "@dataclass\n",
    "class PerformanceMetric:\n",
    "    \"\"\"Structure for performance measurements\"\"\"\n",
    "    operation: str\n",
    "    duration: float\n",
    "    timestamp: datetime\n",
    "    memory_usage: float\n",
    "    context: Dict[str, Any]\n",
    "\n",
    "class PerformanceMonitor:\n",
    "    \"\"\"Monitor and analyze system performance\"\"\"\n",
    "    \n",
    "    FRAMEWORK_PATTERNS = [\n",
    "        r'.*python.*[\\\\/]asyncio[\\\\/].*',\n",
    "        r'.*python.*[\\\\/]ipykernel[\\\\/].*',\n",
    "        r'.*python.*[\\\\/]tornado[\\\\/].*',\n",
    "        r'.*python.*[\\\\/]zmq[\\\\/].*'\n",
    "    ]\n",
    "    \n",
    "    def __init__(self, window_size: int = 1000):\n",
    "        self.metrics: deque = deque(maxlen=window_size)\n",
    "        self.start_time = datetime.now()\n",
    "        self.process = psutil.Process()\n",
    "        self._cached_initial_memory = None\n",
    "        self._framework_regex = [re.compile(pattern) for pattern in self.FRAMEWORK_PATTERNS]\n",
    "    \n",
    "    @property\n",
    "    def initial_memory(self):\n",
    "        \"\"\"Get or compute initial memory usage\"\"\"\n",
    "        if self._cached_initial_memory is None:\n",
    "            self._cached_initial_memory = self.process.memory_info().rss / (1024 * 1024)\n",
    "        return self._cached_initial_memory\n",
    "    \n",
    "    def measure(self, operation: str = None):\n",
    "        \"\"\"Decorator to measure operation performance\"\"\"\n",
    "        def decorator(func):\n",
    "            @wraps(func)\n",
    "            def wrapper(*args, **kwargs):\n",
    "                # Force garbage collection before measurement\n",
    "                import gc\n",
    "                gc.collect()\n",
    "                \n",
    "                start_time = time.perf_counter()\n",
    "                start_memory = self.process.memory_info().rss / (1024 * 1024)  # MB\n",
    "                \n",
    "                try:\n",
    "                    result = func(*args, **kwargs)\n",
    "                    success = True\n",
    "                except Exception as e:\n",
    "                    result = e\n",
    "                    success = False\n",
    "                    raise\n",
    "                finally:\n",
    "                    end_time = time.perf_counter()\n",
    "                    # Force GC again to get accurate memory measurement\n",
    "                    gc.collect()\n",
    "                    end_memory = self.process.memory_info().rss / (1024 * 1024)\n",
    "                    \n",
    "                    metric = PerformanceMetric(\n",
    "                        operation=operation or func.__name__,\n",
    "                        duration=end_time - start_time,\n",
    "                        timestamp=datetime.now(),\n",
    "                        memory_usage=end_memory - start_memory,\n",
    "                        context={\n",
    "                            'success': success,\n",
    "                            'args_length': len(args),\n",
    "                            'kwargs_keys': list(kwargs.keys()),\n",
    "                            'total_memory': end_memory - self.initial_memory\n",
    "                        }\n",
    "                    )\n",
    "                    self.metrics.append(metric)\n",
    "                \n",
    "                return result\n",
    "            return wrapper\n",
    "        return decorator\n",
    "    \n",
    "    def get_statistics(self, operation: str = None, \n",
    "                      time_window: timedelta = None) -> Dict[str, Any]:\n",
    "        \"\"\"Calculate performance statistics\"\"\"\n",
    "        if time_window:\n",
    "            cutoff = datetime.now() - time_window\n",
    "            metrics = [m for m in self.metrics if m.timestamp > cutoff]\n",
    "        else:\n",
    "            metrics = list(self.metrics)\n",
    "        \n",
    "        if operation:\n",
    "            metrics = [m for m in metrics if m.operation == operation]\n",
    "        \n",
    "        if not metrics:\n",
    "            return {}\n",
    "        \n",
    "        durations = [m.duration for m in metrics]\n",
    "        memory_usages = [m.memory_usage for m in metrics]\n",
    "        total_time = (metrics[-1].timestamp - metrics[0].timestamp).total_seconds()\n",
    "        \n",
    "        return {\n",
    "            'count': len(metrics),\n",
    "            'avg_duration': sum(durations) / len(durations),\n",
    "            'max_duration': max(durations),\n",
    "            'min_duration': min(durations),\n",
    "            'avg_memory_delta': sum(memory_usages) / len(memory_usages),\n",
    "            'max_memory_delta': max(memory_usages),\n",
    "            'total_memory': metrics[-1].context['total_memory'],\n",
    "            'operations_per_second': len(metrics) / max(total_time, 0.001),\n",
    "            'total_time': total_time\n",
    "        }\n",
    "    \n",
    "    def _is_framework_file(self, filename: str) -> bool:\n",
    "        \"\"\"Check if a file is a framework internal\"\"\"\n",
    "        return any(pattern.match(filename) for pattern in self._framework_regex)\n",
    "    \n",
    "    def profile_operation(self, func, *args, **kwargs):\n",
    "        \"\"\"Profile a specific operation with framework filtering\"\"\"\n",
    "        # Create profiler and run operation\n",
    "        profiler = cProfile.Profile()\n",
    "        result = profiler.runcall(func, *args, **kwargs)\n",
    "        \n",
    "        # Create filtered stats object\n",
    "        stats = pstats.Stats(profiler)\n",
    "        stats.sort_stats('cumulative')\n",
    "        \n",
    "        # Filter framework calls and create new stats\n",
    "        filtered_entries = {}\n",
    "        for (filename, lineno, funcname), (cc, nc, tt, ct, callers) in stats.stats.items():\n",
    "            if not self._is_framework_file(filename):\n",
    "                filtered_entries[(filename, lineno, funcname)] = (cc, nc, tt, ct, callers)\n",
    "        \n",
    "        filtered_stats = pstats.Stats(profiler)\n",
    "        filtered_stats.stats = filtered_entries\n",
    "        filtered_stats.sort_stats('cumulative')\n",
    "        \n",
    "        return result, filtered_stats\n",
    "\n",
    "# Performance Monitor Demo\n",
    "print(\"\\033[1mPerformance Monitoring Demo\\033[0m\")\n",
    "print(\"=\" * 25)\n",
    "monitor = PerformanceMonitor()\n",
    "\n",
    "@monitor.measure(\"process_instruction\")\n",
    "def process_instruction(content: str) -> Dict[str, Any]:\n",
    "    \"\"\"Example processing function\"\"\"\n",
    "    time.sleep(0.1)  # Simulate work\n",
    "    return {\"status\": \"processed\", \"length\": len(content)}\n",
    "\n",
    "# 1. Content Size Testing\n",
    "print(\"\\n\\033[1m1. Content Size Performance\\033[0m\")\n",
    "print(\"-\" * 25)\n",
    "sizes = [10, 100, 1000]\n",
    "for size in sizes:\n",
    "    content = \"x\" * size\n",
    "    result = process_instruction(content)\n",
    "    print(f\"Processed {size:4d} chars -> {result}\")\n",
    "\n",
    "# 2. Statistics Report\n",
    "print(\"\\n\\033[1m2. Performance Metrics\\033[0m\")\n",
    "print(\"-\" * 25)\n",
    "stats = monitor.get_statistics(operation=\"process_instruction\")\n",
    "metrics = {\n",
    "    \"Total Operations\": stats[\"count\"],\n",
    "    \"Average Duration\": f\"{stats['avg_duration']:.4f}s\",\n",
    "    \"Operations/Second\": f\"{stats['operations_per_second']:.2f}\",\n",
    "    \"Memory Impact\": f\"{stats['avg_memory_delta']:.2f} MB\",\n",
    "    \"Total Runtime\": f\"{stats['total_time']:.3f}s\"\n",
    "}\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key:20}: {value}\")\n",
    "\n",
    "# 3. Profile Analysis\n",
    "print(\"\\n\\033[1m3. Profile Analysis\\033[0m\")\n",
    "print(\"-\" * 25)\n",
    "test_size = 100\n",
    "print(f\"Sample profiling ({test_size} chars):\")\n",
    "result, profile_stats = monitor.profile_operation(\n",
    "    process_instruction, \"x\" * test_size\n",
    ")\n",
    "\n",
    "# Format profile output\n",
    "s = io.StringIO()\n",
    "profile_stats.stream = s\n",
    "profile_stats.sort_stats('cumulative').print_stats(5)\n",
    "\n",
    "# Clean up profile output\n",
    "print(\"\\nTop Operations (excluding framework):\")\n",
    "profile_output = s.getvalue().split('\\n')\n",
    "# Print header\n",
    "print(\"\\n\".join(line for line in profile_output[:3] if line.strip()))\n",
    "# Print stats table header\n",
    "print(\"-\" * 85)\n",
    "print(\"{:>8s} {:>8s} {:>8s} {:>8s} {:>8s}  {}\".format(\n",
    "    \"ncalls\", \"tottime\", \"percall\", \"cumtime\", \"percall\", \"filename:lineno(function)\"))\n",
    "print(\"-\" * 85)\n",
    "# Print actual stats (up to 5 lines)\n",
    "stats_lines = [line for line in profile_output[3:] if line.strip()][:5]\n",
    "print(\"\\n\".join(stats_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834d4564",
   "metadata": {},
   "source": [
    "### Using the Performance Monitor\n",
    "\n",
    "To monitor performance in the Glimpse system:\n",
    "\n",
    "1. **Wrap Components**\n",
    "```python\n",
    "@monitor.measure(\"input_processing\")\n",
    "def process_input(self, content: str):\n",
    "    # Processing logic here\n",
    "    pass\n",
    "```\n",
    "\n",
    "2. **Track Critical Paths**\n",
    "```python\n",
    "@monitor.measure(\"trajectory_analysis\")\n",
    "def analyze_trajectory(self):\n",
    "    # Analysis logic here\n",
    "    pass\n",
    "```\n",
    "\n",
    "3. **Generate Reports**\n",
    "```python\n",
    "stats = monitor.get_statistics(\n",
    "    operation=\"input_processing\",\n",
    "    time_window=timedelta(minutes=5)\n",
    ")\n",
    "```\n",
    "\n",
    "4. **Profile Bottlenecks**\n",
    "```python\n",
    "result, stats = monitor.profile_operation(\n",
    "    orchestrator.process_input,\n",
    "    content=\"test content\"\n",
    ")\n",
    "stats.print_stats(3)  # Show top 3 operations\n",
    "```\n",
    "\n",
    "The performance monitoring system provides:\n",
    "- Real-time metrics through the `measure` decorator\n",
    "- Historical trends with configurable time windows\n",
    "- Memory usage tracking per operation\n",
    "- Operation profiling with framework filtering\n",
    "- Bottleneck identification using cumulative stats\n",
    "- Garbage collection optimization\n",
    "- Customizable metric collection\n",
    "\n",
    "Key features:\n",
    "1. **Accurate Memory Tracking**\n",
    "   - Forced GC before measurements\n",
    "   - Delta and total memory monitoring\n",
    "   - Per-operation memory impact\n",
    "\n",
    "2. **Framework-Aware Profiling**\n",
    "   - Filters out noise from Python internals\n",
    "   - Focus on application code\n",
    "   - Pattern-based exclusion rules\n",
    "\n",
    "3. **Flexible Statistics**\n",
    "   - Time-windowed analysis\n",
    "   - Operation-specific filtering\n",
    "   - Comprehensive metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0e592f",
   "metadata": {},
   "source": [
    "# Final Documentation\n",
    "\n",
    "## System Architecture Overview\n",
    "\n",
    "### Core Components\n",
    "1. **Server SSE Layer** (`server_sse.py`)\n",
    "   - Event streaming infrastructure\n",
    "   - Request handling and validation\n",
    "   - Client connection management\n",
    "\n",
    "2. **Orchestration Layer** (`realtime_preview.py`)\n",
    "   - Workflow coordination\n",
    "   - Component lifecycle management\n",
    "   - Error handling and recovery\n",
    "\n",
    "3. **Input Processing** (`input_adapter.py`)\n",
    "   - Content normalization\n",
    "   - Edit history tracking\n",
    "   - Suggestion generation\n",
    "\n",
    "4. **Trajectory Analysis** (`core_trajectory.py`)\n",
    "   - Pattern recognition\n",
    "   - Code complexity analysis\n",
    "   - Evolution tracking\n",
    "\n",
    "5. **Visual Rendering** (`visual_renderer.py`)\n",
    "   - Preview generation\n",
    "   - Output format handling\n",
    "   - Render queue management\n",
    "\n",
    "6. **Security Layer** (`security_integration.py`)\n",
    "   - Operation validation\n",
    "   - Permission management\n",
    "   - Event broadcasting\n",
    "\n",
    "### Integration Points\n",
    "- SSE event system for real-time updates\n",
    "- Input processing pipeline\n",
    "- Security validation gates\n",
    "- Visual rendering queue\n",
    "- Inter-component communication\n",
    "- Extension registration system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9f9232",
   "metadata": {},
   "source": [
    "## Implementation Details\n",
    "\n",
    "### 1. Extension System\n",
    "The system supports three main types of extensions:\n",
    "\n",
    "#### Input Adapters\n",
    "- Base class: `InputAdapter`\n",
    "- Key features:\n",
    "  * Custom suggestion providers\n",
    "  * Pattern-based content analysis\n",
    "  * Edit history tracking\n",
    "- Example: `MarkdownInputAdapter` implementation\n",
    "\n",
    "#### Trajectory Analyzers\n",
    "- Core class: `CodeComplexityAnalyzer`\n",
    "- Features:\n",
    "  * Complexity metric calculation\n",
    "  * Pattern recognition\n",
    "  * Trend analysis\n",
    "- Integration with `TrajectoryEngine`\n",
    "\n",
    "#### Performance Monitoring\n",
    "- Core class: `PerformanceMonitor`\n",
    "- Capabilities:\n",
    "  * Real-time metrics tracking\n",
    "  * Memory usage analysis\n",
    "  * Framework-aware profiling\n",
    "  * Statistical analysis\n",
    "\n",
    "### 2. Client Integration\n",
    "\n",
    "#### Python Client Implementation\n",
    "```python\n",
    "client = GlimpseClient(server_url=\"http://127.0.0.1:8765\")\n",
    "client.connect()\n",
    "client.on_preview(handle_preview)\n",
    "client.send_input(\"content\")\n",
    "```\n",
    "\n",
    "Key Features:\n",
    "- Automatic reconnection\n",
    "- Event handling\n",
    "- Preview updates\n",
    "- Connection lifecycle management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5dee60",
   "metadata": {},
   "source": [
    "## Deployment & Operations\n",
    "\n",
    "### 1. Performance Optimization\n",
    "- Framework filtering for accurate profiling\n",
    "- Garbage collection optimization\n",
    "- Memory usage tracking\n",
    "- Operation-specific metrics\n",
    "\n",
    "### 2. Security Measures\n",
    "- Input validation and sanitization\n",
    "- Rate limiting implementation\n",
    "- Authentication system\n",
    "- Permission management\n",
    "\n",
    "### 3. Monitoring & Maintenance\n",
    "- Real-time performance tracking\n",
    "- Memory usage analysis\n",
    "- Operation profiling\n",
    "- Error tracking and logging\n",
    "\n",
    "### 4. Deployment Checklist\n",
    "1. **Environment Setup**\n",
    "   - Configure reverse proxy\n",
    "   - Set up monitoring\n",
    "   - Initialize logging system\n",
    "\n",
    "2. **Security Configuration**\n",
    "   - Enable authentication\n",
    "   - Configure rate limits\n",
    "   - Set up SSL/TLS\n",
    "\n",
    "3. **Performance Tuning**\n",
    "   - Optimize garbage collection\n",
    "   - Configure thread pools\n",
    "   - Set memory limits\n",
    "\n",
    "4. **Monitoring Setup**\n",
    "   - Configure metrics collection\n",
    "   - Set up alerting\n",
    "   - Enable log aggregation\n",
    "\n",
    "## Future Enhancements\n",
    "\n",
    "### 1. Technical Improvements\n",
    "- API versioning system\n",
    "- Plugin architecture\n",
    "- Enhanced telemetry\n",
    "- Batch processing support\n",
    "\n",
    "### 2. Feature Additions\n",
    "- Advanced trajectory analysis\n",
    "- Machine learning integration\n",
    "- Real-time collaboration\n",
    "- Extended plugin support\n",
    "\n",
    "### 3. Infrastructure\n",
    "- Container orchestration\n",
    "- Service mesh integration\n",
    "- Distributed tracing\n",
    "- Automated scaling\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The instruction processing pipeline provides a robust foundation for real-time code analysis and preview generation. Key strengths include:\n",
    "\n",
    "1. **Extensibility**\n",
    "   - Modular architecture\n",
    "   - Plugin system\n",
    "   - Custom adapters\n",
    "\n",
    "2. **Performance**\n",
    "   - Efficient processing\n",
    "   - Memory optimization\n",
    "   - Real-time metrics\n",
    "\n",
    "3. **Reliability**\n",
    "   - Error handling\n",
    "   - Automatic recovery\n",
    "   - State management\n",
    "\n",
    "4. **Security**\n",
    "   - Input validation\n",
    "   - Access control\n",
    "   - Secure communication\n",
    "\n",
    "The system is designed to scale and adapt to future requirements while maintaining high performance and reliability standards."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
