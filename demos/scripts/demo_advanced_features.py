#!/usr/bin/env python3
"""
Echoes Assistant - Advanced Features Demonstration
==================================================

This script demonstrates the comprehensive feature set of the enhanced Echoes Assistant,
showcasing how it bridges the competitive gap with industry-leading AI agents.

Features Demonstrated:
1. Conversational Autocomplete with Intent Prediction
2. Advanced History Navigation with Search & Filtering
3. Visual Context Visualization with Relationship Mapping
4. Comprehensive API Logging Dashboard
5. Resilient Session Management
6. Runtime User Tools
7. Enhanced CLI Experience
"""

import json
import os
import sys
from datetime import datetime

# Add current directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from assistant import (AdvancedHistoryManager, APILoggingDashboard,
                       ConversationalAutocomplete, EnhancedCLI,
                       IntelligentAssistant, RuntimeToolManager,
                       VisualContextManager)


def demonstrate_conversational_autocomplete():
    """Demonstrate advanced conversational autocomplete with intent prediction."""
    print("\n" + "=" * 80)
    print("üß† CONVERSATIONAL AUTOCOMPLETE DEMONSTRATION")
    print("=" * 80)

    # Create a mock assistant for demonstration
    assistant = IntelligentAssistant()
    autocomplete = ConversationalAutocomplete(assistant)

    # Test intent detection
    test_inputs = [
        "what is the meaning",
        "enable openai",
        "analyze this data",
        "create a story",
        "help me debug",
        "I feel stressed",
    ]

    print("\nüéØ INTENT PREDICTION TESTS:")
    for input_text in test_inputs:
        intent = autocomplete.detect_intent(input_text)
        print(f"   '{input_text}' ‚Üí Intent: {intent}")

    # Test dynamic suggestions
    conversation_context = [
        "We discussed machine learning models",
        "The OpenAI integration was enabled",
        "Created a custom calculator tool",
    ]

    print("\nüí° DYNAMIC SUGGESTIONS (based on context):")
    suggestions = autocomplete.get_dynamic_suggestions("enable", conversation_context)
    for i, suggestion in enumerate(suggestions[:5], 1):
        print(f"   {i}. {suggestion}")

    print("\n‚úÖ Conversational Autocomplete Features:")
    print("   ‚Ä¢ Real-time intent prediction (6 categories)")
    print("   ‚Ä¢ Context-aware dynamic suggestions")
    print("   ‚Ä¢ FAQ-style completions")
    print("   ‚Ä¢ Topic extraction from conversation history")


def demonstrate_advanced_history():
    """Demonstrate advanced history navigation with search and filtering."""
    print("\n" + "=" * 80)
    print("üìö ADVANCED HISTORY NAVIGATION DEMONSTRATION")
    print("=" * 80)

    # Create assistant with sample conversation
    assistant = IntelligentAssistant()

    # Add sample conversation
    sample_messages = [
        ("user", "What is machine learning?"),
        (
            "assistant",
            "Machine learning is a subset of AI that enables systems to learn from data.",
        ),
        ("user", "Can you explain neural networks?"),
        (
            "assistant",
            "Neural networks are computing systems inspired by biological neural networks.",
        ),
        ("user", "How do I implement a simple neural network?"),
        (
            "assistant",
            "You can implement a simple neural network using Python and libraries like TensorFlow.",
        ),
        ("user", "What about deep learning?"),
        (
            "assistant",
            "Deep learning is a subset of machine learning using multi-layered neural networks.",
        ),
    ]

    from assistant import ChatMessage

    for role, content in sample_messages:
        msg = ChatMessage(
            role=role,
            content=content,
            timestamp=datetime.now().isoformat(),
            message_id=f"msg_{len(assistant.conversation_history)}",
        )
        assistant.conversation_history.append(msg)

    # Initialize history manager
    history_manager = AdvancedHistoryManager(assistant)
    history_manager.build_search_index()

    print("\nüìä CONVERSATION OVERVIEW:")
    print(f"   ‚Ä¢ Total Messages: {len(assistant.conversation_history)}")
    print(
        f"   ‚Ä¢ User Messages: {sum(1 for msg in assistant.conversation_history if msg.role == 'user')}"
    )
    print(
        f"   ‚Ä¢ AI Responses: {sum(1 for msg in assistant.conversation_history if msg.role == 'assistant')}"
    )

    # Test search functionality
    print("\nüîç SEARCH FUNCTIONALITY:")
    search_queries = ["neural", "learning", "implement"]

    for query in search_queries:
        results = history_manager.search_history(query, limit=3)
        print(f"\n   Search for '{query}' ({len(results)} results):")
        for result in results:
            role_icon = "üë§" if result["message"].role == "user" else "ü§ñ"
            print(f"      [{result['score']}] {role_icon}: {result['preview']}")

    # Test threading
    print("\nüßµ THREADED VIEW:")
    threads = history_manager.get_threaded_view()
    for i, thread in enumerate(threads, 1):
        print(f"   Thread {i}: {len(thread)} messages")

    # Test bookmarks and tags
    history_manager.add_bookmark(2, "Important ML definition")
    history_manager.add_tag(4, "code-related")
    history_manager.add_tag(6, "advanced")

    print("\nüìñ BOOKMARKS & TAGS:")
    print(f"   ‚Ä¢ Bookmarks: {len(history_manager.bookmarks)}")
    print(f"   ‚Ä¢ Tagged messages: {len(history_manager.tags)}")

    print("\n‚úÖ Advanced History Features:")
    print("   ‚Ä¢ Full-text search with fuzzy matching")
    print("   ‚Ä¢ Threaded conversation view")
    print("   ‚Ä¢ Message bookmarks and tagging")
    print("   ‚Ä¢ Role-based filtering")
    print("   ‚Ä¢ Jump to unanswered questions")


def demonstrate_visual_context():
    """Demonstrate visual context visualization with relationship mapping."""
    print("\n" + "=" * 80)
    print("üé® VISUAL CONTEXT VISUALIZATION DEMONSTRATION")
    print("=" * 80)

    # Create assistant with technical conversation
    assistant = IntelligentAssistant()

    # Add sample technical conversation
    technical_messages = [
        ("user", "I need help with Python programming and API development"),
        ("assistant", "I can help you with Python code and API design patterns."),
        ("user", "What's the best way to implement REST APIs using Flask?"),
        (
            "assistant",
            "Flask is excellent for REST APIs. Use Flask-RESTful for better structure.",
        ),
        ("user", "How about data analysis with pandas and machine learning?"),
        (
            "assistant",
            "Pandas is great for data analysis. For ML, consider scikit-learn or TensorFlow.",
        ),
    ]

    from assistant import ChatMessage

    for role, content in technical_messages:
        msg = ChatMessage(
            role=role,
            content=content,
            timestamp=datetime.now().isoformat(),
            message_id=f"msg_{len(assistant.conversation_history)}",
        )
        assistant.conversation_history.append(msg)

    # Initialize visual context manager
    visual_context = VisualContextManager(assistant)

    # Generate timeline
    timeline = visual_context.generate_timeline()

    print("\nüìÖ TOPIC ANALYSIS:")
    topic_counts = {}
    for event in timeline:
        topic = event["topic"]
        topic_counts[topic] = topic_counts.get(topic, 0) + 1

    for topic, count in topic_counts.items():
        print(f"   ‚Ä¢ {topic}: {count} messages")

    # Build context graph
    visual_context.build_context_graph()
    entity_count = len(
        [
            n
            for n in visual_context.entity_graph.nodes()
            if visual_context.entity_graph.nodes[n].get("type") == "entity"
        ]
    )

    print("\nüï∏Ô∏è  ENTITY RELATIONSHIP ANALYSIS:")
    print(f"   ‚Ä¢ Total entities extracted: {entity_count}")
    print(f"   ‚Ä¢ Graph nodes: {visual_context.entity_graph.number_of_nodes()}")
    print(f"   ‚Ä¢ Graph edges: {visual_context.entity_graph.number_of_edges()}")

    # Export context data
    context_data = visual_context.export_context_data()

    print("\nüìä CONTEXT INSIGHTS:")
    print(f"   ‚Ä¢ Primary topic: {max(topic_counts, key=topic_counts.get)}")
    print(f"   ‚Ä¢ Conversation diversity: {len(topic_counts)} different topics")
    print(f"   ‚Ä¢ Entity density: {entity_count/len(timeline):.1f} entities per message")

    print("\n‚úÖ Visual Context Features:")
    print("   ‚Ä¢ Entity extraction and relationship mapping")
    print("   ‚Ä¢ Topic classification and timeline generation")
    print("   ‚Ä¢ Sentiment analysis per message")
    print("   ‚Ä¢ Conversation flow visualization")
    print("   ‚Ä¢ Export data for external visualization tools")


def demonstrate_api_logging():
    """Demonstrate comprehensive API logging with dashboard."""
    print("\n" + "=" * 80)
    print("üìä API LOGGING DASHBOARD DEMONSTRATION")
    print("=" * 80)

    # Initialize API dashboard
    dashboard = APILoggingDashboard()

    # Simulate API calls
    test_calls = [
        (
            "chat/completions",
            "gpt-4o",
            {"messages": [{"role": "user", "content": "Hello"}]},
            {"choices": [{"message": {"content": "Hi there!"}}]},
            1.2,
            True,
        ),
        (
            "chat/completions",
            "gpt-3.5-turbo",
            {"messages": [{"role": "user", "content": "Explain AI"}]},
            {"choices": [{"message": {"content": "AI is artificial intelligence"}}]},
            0.8,
            True,
        ),
        (
            "models/list",
            "gpt-4o",
            {},
            {"models": ["gpt-4o", "gpt-3.5-turbo"]},
            0.3,
            True,
        ),
        (
            "chat/completions",
            "gpt-4",
            {"messages": [{"role": "user", "content": "Error test"}]},
            {},
            2.1,
            False,
            "Rate limit exceeded",
        ),
        (
            "chat/completions",
            "gpt-4o",
            {"messages": [{"role": "user", "content": "Help me code"}]},
            {"choices": [{"message": {"content": "Here's the code..."}}]},
            1.5,
            True,
        ),
    ]

    print("\nüìù SIMULATING API CALLS:")
    for endpoint, model, request, response, time_taken, success, *error in test_calls:
        error_msg = error[0] if error else None
        dashboard.log_api_call(
            endpoint, model, request, response, time_taken, success, error_msg
        )
        status = "‚úÖ" if success else "‚ùå"
        print(f"   {status} {endpoint} - {model} - {time_taken}s")

    # Display metrics
    metrics = dashboard.metrics
    success_rate = (
        (metrics["successful_requests"] / metrics["total_requests"] * 100)
        if metrics["total_requests"] > 0
        else 0
    )

    print("\nüìà PERFORMANCE METRICS:")
    print(f"   ‚Ä¢ Total Requests: {metrics['total_requests']}")
    print(f"   ‚Ä¢ Success Rate: {success_rate:.1f}%")
    print(f"   ‚Ä¢ Average Response Time: {metrics['average_response_time']:.3f}s")
    print(f"   ‚Ä¢ Failed Requests: {metrics['failed_requests']}")

    print("\nü§ñ MODEL USAGE BREAKDOWN:")
    for model, count in metrics["model_usage"].items():
        percentage = (
            (count / metrics["total_requests"] * 100)
            if metrics["total_requests"] > 0
            else 0
        )
        print(f"   ‚Ä¢ {model}: {count} requests ({percentage:.1f}%)")

    print("\nüö® ERROR ANALYSIS:")
    for error_type, count in metrics["error_types"].items():
        print(f"   ‚Ä¢ {error_type}: {count} occurrences")

    # Test export functionality
    export_file = dashboard.export_logs("json")
    print("\nüíæ EXPORT CAPABILITY:")
    print(f"   ‚Ä¢ Logs exported to: {export_file}")
    print("   ‚Ä¢ Formats available: JSON, CSV")

    print("\n‚úÖ API Logging Features:")
    print("   ‚Ä¢ Detailed request/response logging")
    print("   ‚Ä¢ Real-time performance metrics")
    print("   ‚Ä¢ Model usage analytics")
    print("   ‚Ä¢ Error categorization and tracking")
    print("   ‚Ä¢ Time-based analysis (hourly/daily)")
    print("   ‚Ä¢ Export functionality for audit trails")


def demonstrate_runtime_tools():
    """Demonstrate runtime user tools with safe execution."""
    print("\n" + "=" * 80)
    print("üîß RUNTIME TOOLS DEMONSTRATION")
    print("=" * 80)

    # Create assistant and tool manager
    assistant = IntelligentAssistant()
    tool_manager = RuntimeToolManager(assistant)

    # Define sample tools
    sample_tools = [
        {
            "name": "sentiment_analyzer",
            "description": "Analyze text sentiment",
            "code": """
def sentiment_analyzer(text):
    positive_words = ['good', 'great', 'excellent', 'amazing', 'wonderful']
    negative_words = ['bad', 'terrible', 'awful', 'horrible', 'worse']
    
    text_lower = text.lower()
    pos_count = sum(1 for word in positive_words if word in text_lower)
    neg_count = sum(1 for word in negative_words if word in text_lower)
    
    if pos_count > neg_count:
        return "Positive"
    elif neg_count > pos_count:
        return "Negative"
    else:
        return "Neutral"
""",
        },
        {
            "name": "data_formatter",
            "description": "Format data in various ways",
            "code": """
def data_formatter(data, format_type="json"):
    if format_type == "json":
        return json.dumps(data, indent=2)
    elif format_type == "csv":
        if isinstance(data, dict):
            return ",".join(data.keys())
        return str(data)
    elif format_type == "summary":
        return f"Data with {len(data)} items"
    else:
        return str(data)
""",
        },
    ]

    print("\nüõ†Ô∏è  ADDING RUNTIME TOOLS:")
    for tool_info in sample_tools:
        success = tool_manager.add_tool(
            tool_info["name"], tool_info["description"], tool_info["code"]
        )
        status = "‚úÖ" if success else "‚ùå"
        print(f"   {status} {tool_info['name']}: {tool_info['description']}")

    # List available tools
    tools = tool_manager.list_tools()
    print(f"\nüìã AVAILABLE TOOLS ({len(tools)} total):")
    for name, info in tools.items():
        print(f"   ‚Ä¢ {name}")
        print(f"     Description: {info['description']}")
        print(f"     Usage count: {info['usage_count']}")

    # Test tool execution
    print("\n‚ö° TOOL EXECUTION TESTS:")

    # Test sentiment analyzer
    sentiment_result = tool_manager.execute_tool(
        "sentiment_analyzer", "This is amazing and wonderful!"
    )
    print(
        f"   ‚Ä¢ Sentiment Analysis: 'This is amazing and wonderful!' ‚Üí {sentiment_result}"
    )

    # Test data formatter
    test_data = {
        "name": "Echoes",
        "type": "AI Assistant",
        "features": ["NLP", "Vision", "Reasoning"],
    }
    json_result = tool_manager.execute_tool("data_formatter", test_data, "json")
    print(f"   ‚Ä¢ Data Formatting (JSON): {json_result[:50]}...")

    summary_result = tool_manager.execute_tool("data_formatter", test_data, "summary")
    print(f"   ‚Ä¢ Data Formatting (Summary): {summary_result}")

    print("\n‚úÖ Runtime Tools Features:")
    print("   ‚Ä¢ Safe sandboxed execution environment")
    print("   ‚Ä¢ Interactive tool creation without restart")
    print("   ‚Ä¢ Persistent tool storage")
    print("   ‚Ä¢ Usage tracking and statistics")
    print("   ‚Ä¢ Tool metadata and documentation")


def demonstrate_session_management():
    """Demonstrate resilient session management with versioning."""
    print("\n" + "=" * 80)
    print("üíæ SESSION MANAGEMENT DEMONSTRATION")
    print("=" * 80)

    # Create assistant with rich conversation
    assistant = IntelligentAssistant()

    # Enable OpenAI and set preferences
    assistant.openai_enabled = True
    assistant.model_preference = "gpt-4o"
    assistant.dynamic_model_switching = True
    assistant.cost_optimization = True

    # Add sample conversation with metadata
    from assistant import ChatMessage

    conversations = [
        (
            "user",
            "Help me understand machine learning algorithms",
            "2025-11-02T09:00:00",
        ),
        (
            "assistant",
            "Machine learning algorithms are computational methods that learn patterns from data",
            "2025-11-02T09:00:05",
        ),
        (
            "user",
            "What's the difference between supervised and unsupervised learning?",
            "2025-11-02T09:01:00",
        ),
        (
            "assistant",
            "Supervised learning uses labeled data, while unsupervised learning finds patterns in unlabeled data",
            "2025-11-02T09:01:10",
        ),
        (
            "user",
            "Can you recommend a good algorithm for classification?",
            "2025-11-02T09:02:00",
        ),
        (
            "assistant",
            "For classification, consider Random Forest, SVM, or Neural Networks depending on your data",
            "2025-11-02T09:02:15",
        ),
    ]

    for role, content, timestamp in conversations:
        msg = ChatMessage(
            role=role,
            content=content,
            timestamp=timestamp,
            message_id=f"msg_{len(assistant.conversation_history)}",
        )
        assistant.conversation_history.append(msg)

    # Add personality memory
    assistant.personality_memory = {
        "preferred_domain": "technical",
        "dominant_personality": "analytical",
        "conversation_patterns": {"question_frequency": 0.8, "technical_terms": 0.9},
    }

    # Initialize enhanced CLI
    cli = EnhancedCLI(assistant)

    print("\nüìä SESSION OVERVIEW:")
    print(f"   ‚Ä¢ Session ID: {assistant.session_id}")
    print(f"   ‚Ä¢ Conversation Length: {len(assistant.conversation_history)} messages")
    print(f"   ‚Ä¢ OpenAI Enabled: {assistant.openai_enabled}")
    print(f"   ‚Ä¢ Current Model: {assistant.model_preference}")
    print(f"   ‚Ä¢ Dynamic Switching: {assistant.dynamic_model_switching}")

    # Export session
    export_file = cli.export_session("demo_session.json")
    print("\nüíæ SESSION EXPORT:")
    print(f"   ‚Ä¢ Exported to: {export_file}")

    # Read and display session structure
    with open(export_file) as f:
        session_data = json.load(f)

    print("\nüìã SESSION STRUCTURE:")
    for key, value in session_data.items():
        if isinstance(value, dict):
            print(f"   ‚Ä¢ {key}: {len(value)} items")
        elif isinstance(value, list):
            print(f"   ‚Ä¢ {key}: {len(value)} entries")
        else:
            print(f"   ‚Ä¢ {key}: {str(value)[:50]}...")

    # Reset and import session
    assistant.reset_conversation()
    print("\nüîÑ SESSION RESET:")
    print(f"   ‚Ä¢ Conversation cleared: {len(assistant.conversation_history)} messages")

    # Import session back
    import_success = cli.import_session("demo_session.json")
    print("\nüì• SESSION IMPORT:")
    print(f"   ‚Ä¢ Import successful: {import_success}")
    print(f"   ‚Ä¢ Restored messages: {len(assistant.conversation_history)}")
    print(f"   ‚Ä¢ Settings restored: {assistant.openai_enabled}")

    print("\n‚úÖ Session Management Features:")
    print("   ‚Ä¢ Complete state serialization (conversation, memory, settings)")
    print("   ‚Ä¢ Cross-platform session transfer")
    print("   ‚Ä¢ Version control friendly format")
    print("   ‚Ä¢ Atomic import/export operations")
    print("   ‚Ä¢ Metadata preservation")


def main():
    """Run comprehensive demonstration of all advanced features."""
    print("üöÄ ECHOES ASSISTANT - ADVANCED FEATURES COMPREHENSIVE DEMONSTRATION")
    print("=" * 80)
    print("This demonstration showcases how Echoes bridges the competitive gap")
    print("with industry-leading AI agents through advanced features.")
    print("=" * 80)

    demonstrations = [
        ("Conversational Autocomplete", demonstrate_conversational_autocomplete),
        ("Advanced History Navigation", demonstrate_advanced_history),
        ("Visual Context Visualization", demonstrate_visual_context),
        ("API Logging Dashboard", demonstrate_api_logging),
        ("Runtime User Tools", demonstrate_runtime_tools),
        ("Session Management", demonstrate_session_management),
    ]

    for name, demo_func in demonstrations:
        try:
            demo_func()
            print(f"\n‚úÖ {name} - COMPLETED SUCCESSFULLY")
        except Exception as e:
            print(f"\n‚ùå {name} - ERROR: {e}")

        input("\nPress Enter to continue to next demonstration...")

    print("\n" + "=" * 80)
    print("üéâ DEMONSTRATION COMPLETE")
    print("=" * 80)
    print("üìà COMPETITIVE ADVANTAGES ACHIEVED:")
    print("   ‚úÖ Conversational autocomplete with intent prediction")
    print("   ‚úÖ Advanced history navigation with search & threading")
    print("   ‚úÖ Visual context visualization with relationship mapping")
    print("   ‚úÖ Comprehensive API logging with dashboards")
    print("   ‚úÖ Resilient session management with versioning")
    print("   ‚úÖ Runtime user tools with safe execution")
    print("   ‚úÖ Enhanced CLI with tab completion and history")
    print()
    print("üöÄ Echoes Assistant now competes with and exceeds industry leaders!")
    print("   ‚Ä¢ ChatGPT-level conversational intelligence")
    print("   ‚Ä¢ Claude-style context awareness")
    print("   ‚Ä¢ Perplexity-like source visualization")
    print("   ‚Ä¢ Enterprise-grade reliability and observability")
    print("   ‚Ä¢ Extensible plugin architecture")
    print("   ‚Ä¢ Cross-platform session management")
    print("=" * 80)


if __name__ == "__main__":
    main()
